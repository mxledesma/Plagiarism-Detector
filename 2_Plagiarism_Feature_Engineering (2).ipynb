{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plagiarism Detection, Feature Engineering\n",
    "\n",
    "In this project, you will be tasked with building a plagiarism detector that examines an answer text file and performs binary classification; labeling that file as either plagiarized or not, depending on how similar that text file is to a provided, source text. \n",
    "\n",
    "Your first task will be to create some features that can then be used to train a classification model. This task will be broken down into a few discrete steps:\n",
    "\n",
    "* Clean and pre-process the data.\n",
    "* Define features for comparing the similarity of an answer text and a source text, and extract similarity features.\n",
    "* Select \"good\" features, by analyzing the correlations between different features.\n",
    "* Create train/test `.csv` files that hold the relevant features and class labels for train/test data points.\n",
    "\n",
    "In the _next_ notebook, Notebook 3, you'll use the features and `.csv` files you create in _this_ notebook to train a binary classification model in a SageMaker notebook instance.\n",
    "\n",
    "You'll be defining a few different similarity features, as outlined in [this paper](https://s3.amazonaws.com/video.udacity-data.com/topher/2019/January/5c412841_developing-a-corpus-of-plagiarised-short-answers/developing-a-corpus-of-plagiarised-short-answers.pdf), which should help you build a robust plagiarism detector!\n",
    "\n",
    "To complete this notebook, you'll have to complete all given exercises and answer all the questions in this notebook.\n",
    "> All your tasks will be clearly labeled **EXERCISE** and questions as **QUESTION**.\n",
    "\n",
    "It will be up to you to decide on the features to include in your final training and test data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the Data\n",
    "\n",
    "The cell below will download the necessary, project data and extract the files into the folder `data/`.\n",
    "\n",
    "This data is a slightly modified version of a dataset created by Paul Clough (Information Studies) and Mark Stevenson (Computer Science), at the University of Sheffield. You can read all about the data collection and corpus, at [their university webpage](https://ir.shef.ac.uk/cloughie/resources/plagiarism_corpus.html). \n",
    "\n",
    "> **Citation for data**: Clough, P. and Stevenson, M. Developing A Corpus of Plagiarised Short Answers, Language Resources and Evaluation: Special Issue on Plagiarism and Authorship Analysis, In Press. [Download]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# you only need to run this cell if you have not yet downloaded the data\n",
    "# otherwise you may skip this cell or comment it out\n",
    "\n",
    "#!wget https://s3.amazonaws.com/video.udacity-data.com/topher/2019/January/5c4147f9_data/data.zip\n",
    "#!unzip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plagiarism dataset is made of multiple text files; each of these files has characteristics that are is summarized in a `.csv` file named `file_information.csv`, which we can read in using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>heavy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task Category\n",
       "0  g0pA_taska.txt    a      non\n",
       "1  g0pA_taskb.txt    b      cut\n",
       "2  g0pA_taskc.txt    c    light\n",
       "3  g0pA_taskd.txt    d    heavy\n",
       "4  g0pA_taske.txt    e      non"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = 'data/file_information.csv'\n",
    "plagiarism_df = pd.read_csv(csv_file)\n",
    "\n",
    "# print out the first few rows of data info\n",
    "plagiarism_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(plagiarism_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "plagiarism_df['Category']=plagiarism_df['Category'].map({'non': 0, 'heavy': 1,'light':2,'cut':3,'orig':-1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   File      100 non-null    object\n",
      " 1   Task      100 non-null    object\n",
      " 2   Category  100 non-null    int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 2.5+ KB\n"
     ]
    }
   ],
   "source": [
    "plagiarism_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>orig_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>orig_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>orig_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>orig_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>orig_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              File Task  Category  Class\n",
       "95  orig_taska.txt    a        -1     -1\n",
       "96  orig_taskb.txt    b        -1     -1\n",
       "97  orig_taskc.txt    c        -1     -1\n",
       "98  orig_taskd.txt    d        -1     -1\n",
       "99  orig_taske.txt    e        -1     -1"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of our conditions\n",
    "\n",
    "def class_label(row):\n",
    "    if row['Category']==0:\n",
    "        return 0\n",
    "    elif row['Category']==1 or row['Category']==2 or row['Category']==3:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "plagiarism_df['Class']=plagiarism_df.apply(lambda row: class_label(row),axis=1)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Any answer text that is not plagiarized (non) should have the class label 0.\n",
    "Any plagiarized answer texts, 'cut','light', and 'heavy', should have the class label 1.\n",
    "And any orig texts will have a special label -1.\n",
    "\"\"\"\n",
    "\n",
    "# display updated DataFrame\n",
    "plagiarism_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Plagiarism\n",
    "\n",
    "Each text file is associated with one **Task** (task A-E) and one **Category** of plagiarism, which you can see in the above DataFrame.\n",
    "\n",
    "###  Tasks, A-E\n",
    "\n",
    "Each text file contains an answer to one short question; these questions are labeled as tasks A-E. For example, Task A asks the question: \"What is inheritance in object oriented programming?\"\n",
    "\n",
    "### Categories of plagiarism \n",
    "\n",
    "Each text file has an associated plagiarism label/category:\n",
    "\n",
    "**1. Plagiarized categories: `cut`, `light`, and `heavy`.**\n",
    "* These categories represent different levels of plagiarized answer texts. `cut` answers copy directly from a source text, `light` answers are based on the source text but include some light rephrasing, and `heavy` answers are based on the source text, but *heavily* rephrased (and will likely be the most challenging kind of plagiarism to detect).\n",
    "     \n",
    "**2. Non-plagiarized category: `non`.** \n",
    "* `non` indicates that an answer is not plagiarized; the Wikipedia source text is not used to create this answer.\n",
    "    \n",
    "**3. Special, source text category: `orig`.**\n",
    "* This is a specific category for the original, Wikipedia source text. We will use these files only for comparison purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pre-Process the Data\n",
    "\n",
    "In the next few cells, you'll be tasked with creating a new DataFrame of desired information about all of the files in the `data/` directory. This will prepare the data for feature extraction and for training a binary, plagiarism classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: Convert categorical to numerical data\n",
    "\n",
    "You'll notice that the `Category` column in the data, contains string or categorical values, and to prepare these for feature extraction, we'll want to convert these into numerical values. Additionally, our goal is to create a binary classifier and so we'll need a binary class label that indicates whether an answer text is plagiarized (1) or not (0). Complete the below function `numerical_dataframe` that reads in a `file_information.csv` file by name, and returns a *new* DataFrame with a numerical `Category` column and a new `Class` column that labels each answer as plagiarized or not. \n",
    "\n",
    "Your function should return a new DataFrame with the following properties:\n",
    "\n",
    "* 4 columns: `File`, `Task`, `Category`, `Class`. The `File` and `Task` columns can remain unchanged from the original `.csv` file.\n",
    "* Convert all `Category` labels to numerical labels according to the following rules (a higher value indicates a higher degree of plagiarism):\n",
    "    * 0 = `non`\n",
    "    * 1 = `heavy`\n",
    "    * 2 = `light`\n",
    "    * 3 = `cut`\n",
    "    * -1 = `orig`, this is a special value that indicates an original file.\n",
    "* For the new `Class` column\n",
    "    * Any answer text that is not plagiarized (`non`) should have the class label `0`. \n",
    "    * Any plagiarized answer texts should have the class label `1`. \n",
    "    * And any `orig` texts will have a special label `-1`. \n",
    "\n",
    "### Expected output\n",
    "\n",
    "After running your function, you should get a DataFrame with rows that looks like the following: \n",
    "```\n",
    "\n",
    "        File\t     Task  Category  Class\n",
    "0\tg0pA_taska.txt\ta\t  0   \t0\n",
    "1\tg0pA_taskb.txt\tb\t  3   \t1\n",
    "2\tg0pA_taskc.txt\tc\t  2   \t1\n",
    "3\tg0pA_taskd.txt\td\t  1   \t1\n",
    "4\tg0pA_taske.txt\te\t  0\t   0\n",
    "...\n",
    "...\n",
    "99   orig_taske.txt    e     -1      -1\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a csv file and return a transformed dataframe\n",
    "def numerical_dataframe(csv_file='data/file_information.csv'):\n",
    "    '''Reads in a csv file which is assumed to have `File`, `Category` and `Task` columns.\n",
    "       This function does two things: \n",
    "       1) converts `Category` column values to numerical values \n",
    "       2) Adds a new, numerical `Class` label column.\n",
    "       The `Class` column will label plagiarized answers as 1 and non-plagiarized as 0.\n",
    "       Source texts have a special label, -1.\n",
    "       :param csv_file: The directory for the file_information.csv file\n",
    "       :return: A dataframe with numerical categories and a new `Class` label column'''\n",
    "    \n",
    "    transformed_df = pd.read_csv(csv_file)\n",
    "    \n",
    "    transformed_df['Category']=transformed_df['Category'].map({'non': 0, 'heavy': 1,'light':2,'cut':3,'orig':-1})\n",
    "    \n",
    "    def class_label(row):\n",
    "        if row['Category']==0:\n",
    "    # Any answer text that is not plagiarized (non) should have the class label 0.        \n",
    "            return 0  \n",
    "        elif row['Category']==1 or row['Category']==2 or row['Category']==3:\n",
    "    # plagiarized answer texts, 'cut','light', and 'heavy', should have the class label 1.\n",
    "            return 1\n",
    "        else:\n",
    "    # any 'orig'  texts will have a special label -1.\n",
    "            return -1\n",
    "    \n",
    "    transformed_df['Class']=transformed_df.apply(lambda row: class_label(row),axis=1)\n",
    "    \n",
    "    return transformed_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cells\n",
    "\n",
    "Below are a couple of test cells. The first is an informal test where you can check that your code is working as expected by calling your function and printing out the returned result.\n",
    "\n",
    "The **second** cell below is a more rigorous test cell. The goal of a cell like this is to ensure that your code is working as expected, and to form any variables that might be used in _later_ tests/code, in this case, the data frame, `transformed_df`.\n",
    "\n",
    "> The cells in this notebook should be run in chronological order (the order they appear in the notebook). This is especially important for test cells.\n",
    "\n",
    "Often, later cells rely on the functions, imports, or variables defined in earlier cells. For example, some tests rely on previous tests to work.\n",
    "\n",
    "These tests do not test all cases, but they are a great way to check that you are on the right track!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>g0pB_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g0pB_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>g0pB_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>g0pB_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>g0pB_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task  Category  Class\n",
       "0  g0pA_taska.txt    a         0      0\n",
       "1  g0pA_taskb.txt    b         3      1\n",
       "2  g0pA_taskc.txt    c         2      1\n",
       "3  g0pA_taskd.txt    d         1      1\n",
       "4  g0pA_taske.txt    e         0      0\n",
       "5  g0pB_taska.txt    a         0      0\n",
       "6  g0pB_taskb.txt    b         0      0\n",
       "7  g0pB_taskc.txt    c         3      1\n",
       "8  g0pB_taskd.txt    d         2      1\n",
       "9  g0pB_taske.txt    e         1      1"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# informal testing, print out the results of a called function\n",
    "# create new `transformed_df`\n",
    "transformed_df = numerical_dataframe(csv_file ='data/file_information.csv')\n",
    "\n",
    "# check work\n",
    "# check that all categories of plagiarism have a class label = 1\n",
    "transformed_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed!\n",
      "\n",
      "Example data: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task  Category  Class\n",
       "0  g0pA_taska.txt    a         0      0\n",
       "1  g0pA_taskb.txt    b         3      1\n",
       "2  g0pA_taskc.txt    c         2      1\n",
       "3  g0pA_taskd.txt    d         1      1\n",
       "4  g0pA_taske.txt    e         0      0"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test cell that creates `transformed_df`, if tests are passed\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "# importing tests\n",
    "import problem_unittests as tests\n",
    "\n",
    "# test numerical_dataframe function\n",
    "tests.test_numerical_df(numerical_dataframe)\n",
    "\n",
    "# if above test is passed, create NEW `transformed_df`\n",
    "transformed_df = numerical_dataframe(csv_file ='data/file_information.csv')\n",
    "\n",
    "# check work\n",
    "print('\\nExample data: ')\n",
    "transformed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing & Splitting Data\n",
    "\n",
    "Recall that the goal of this project is to build a plagiarism classifier. At it's heart, this task is a comparison text; one that looks at a given answer and a source text, compares them and predicts whether an answer has plagiarized from the source. To effectively do this comparison, and train a classifier we'll need to do a few more things: pre-process all of our text data and prepare the text files (in this case, the 95 answer files and 5 original source files) to be easily compared, and split our data into a `train` and `test` set that can be used to train a classifier and evaluate it, respectively. \n",
    "\n",
    "To this end, you've been provided code that adds  additional information to your `transformed_df` from above. The next two cells need not be changed; they add two additional columns to the `transformed_df`:\n",
    "\n",
    "1. A `Text` column; this holds all the lowercase text for a `File`, with extraneous punctuation removed.\n",
    "2. A `Datatype` column; this is a string value `train`, `test`, or `orig` that labels a data point as part of our train or test set\n",
    "\n",
    "The details of how these additional columns are created can be found in the `helpers.py` file in the project directory. You're encouraged to read through that file to see exactly how text is processed and how data is split.\n",
    "\n",
    "Run the cells below to get a `complete_df` that has all the information you need to proceed with plagiarism detection and feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>g4pE_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>object oriented programming is a style of prog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>g4pE_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>pagerankalgorithm is also known as link analys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>g4pE_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>the definition of term depends on the applicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>g4pE_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bayes theorem or bayes rule  or something cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>g4pE_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dynamic programming is a method for efficient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>orig_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>in object oriented programming inheritance is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>orig_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>pagerank is a link analysis algorithm used by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>orig_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>vector space model or term vector model is an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>orig_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>in probability theory bayes theorem often call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>orig_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>in mathematics and computer science dynamic pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              File Task  Category  Class  \\\n",
       "90  g4pE_taska.txt    a         1      1   \n",
       "91  g4pE_taskb.txt    b         2      1   \n",
       "92  g4pE_taskc.txt    c         3      1   \n",
       "93  g4pE_taskd.txt    d         0      0   \n",
       "94  g4pE_taske.txt    e         0      0   \n",
       "95  orig_taska.txt    a        -1     -1   \n",
       "96  orig_taskb.txt    b        -1     -1   \n",
       "97  orig_taskc.txt    c        -1     -1   \n",
       "98  orig_taskd.txt    d        -1     -1   \n",
       "99  orig_taske.txt    e        -1     -1   \n",
       "\n",
       "                                                 Text  \n",
       "90  object oriented programming is a style of prog...  \n",
       "91  pagerankalgorithm is also known as link analys...  \n",
       "92  the definition of term depends on the applicat...  \n",
       "93   bayes theorem or bayes rule  or something cal...  \n",
       "94   dynamic programming is a method for efficient...  \n",
       "95  in object oriented programming inheritance is ...  \n",
       "96  pagerank is a link analysis algorithm used by ...  \n",
       "97  vector space model or term vector model is an ...  \n",
       "98  in probability theory bayes theorem often call...  \n",
       "99  in mathematics and computer science dynamic pr...  "
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "import helpers \n",
    "\n",
    "# create a text column \n",
    "text_df = helpers.create_text_column(transformed_df)\n",
    "text_df.tail(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n"
     ]
    }
   ],
   "source": [
    "print(text_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample processed text:\n",
      "\n",
      " vector space model is an algebraic model for representing text documents and in general any objects as vectors of identifiers such as for example index terms its first use was in the smart information retrieval system it is used in information filtering information retrieval indexing and relevancy rankings  a document is represented as a vector and each dimension corresponds to a separate term if a term occurs in the document its value in the vector is non zero several different ways of computing these values also known as term weights have been developed the definition of term depends on the application typically terms are single words keywords or longer phrases if the words are chosen to be the terms the dimensionality of the vector is the number of words in the vocabulary the number of distinct words occurring in the corpus  one of the best known schemes is tf idf weighting proposed by salton wong and yang in the classic vector space model the term specific weights in the document vectors are products of local and global parameters  relevancy rankings of documents in a keyword search can be calculated using the assumptions of document similarities theory by comparing the deviation of angles between each document vector and the original query vector where the query is represented as same kind of vector as the documents  the vector space model has the following limitations   search keywords must precisely match document terms word substrings might result in a false positive match   semantic sensitivity documents with similar context but different term vocabulary won t be associated resulting in a false negative match   the order in which the terms appear in the document is lost in the vector space representation  long documents are poorly represented because they have poor similarity values a small scalar product and a large dimensionality   <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# after running the cell above\n",
    "# check out the processed text for a single file, by row index\n",
    "row_idx = 7 # feel free to change this index\n",
    "\n",
    "sample_text = (text_df.iloc[row_idx]['Text'])\n",
    "\n",
    "print('Sample processed text:\\n\\n', sample_text,type(sample_text)) # Notice the two empty lines \\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets\n",
    "\n",
    "The next cell will add a `Datatype` column to a given DataFrame to indicate if the record is: \n",
    "* `train` - Training data, for model training.  74% \n",
    "* `test` - Testing data, for model evaluation.  26% \n",
    "* `orig` - The task's original answer from wikipedia.\n",
    "\n",
    "### Stratified sampling\n",
    "\n",
    "The given code uses a helper function which you can view in the `helpers.py` file in the main project directory. This implements [stratified random sampling](https://en.wikipedia.org/wiki/Stratified_sampling) to randomly split data by task & plagiarism amount. Stratified sampling ensures that we get training and test data that is fairly evenly distributed across task & plagiarism combinations. Approximately 26% of the data is held out for testing and 74% of the data is used for training.\n",
    "\n",
    "The function **train_test_dataframe** takes in a DataFrame that it assumes has `Task` and `Category` columns, and, returns a modified frame that indicates which `Datatype` (train, test, or orig) a file falls into. This sampling will change slightly based on a passed in *random_seed*. Due to a small sample size, this stratified random sampling will provide more stable results for a binary plagiarism classifier. Stability here is smaller *variance* in the accuracy of classifier, given a random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              File Task  Category  Class  \\\n",
      "1   g0pA_taskb.txt    b         3      1   \n",
      "2   g0pA_taskc.txt    c         2      1   \n",
      "3   g0pA_taskd.txt    d         1      1   \n",
      "7   g0pB_taskc.txt    c         3      1   \n",
      "8   g0pB_taskd.txt    d         2      1   \n",
      "9   g0pB_taske.txt    e         1      1   \n",
      "10  g0pC_taska.txt    a         1      1   \n",
      "13  g0pC_taskd.txt    d         3      1   \n",
      "14  g0pC_taske.txt    e         2      1   \n",
      "15  g0pD_taska.txt    a         3      1   \n",
      "16  g0pD_taskb.txt    b         2      1   \n",
      "17  g0pD_taskc.txt    c         1      1   \n",
      "20  g0pE_taska.txt    a         2      1   \n",
      "21  g0pE_taskb.txt    b         1      1   \n",
      "24  g0pE_taske.txt    e         3      1   \n",
      "26  g1pA_taskb.txt    b         1      1   \n",
      "27  g1pA_taskc.txt    c         2      1   \n",
      "28  g1pA_taskd.txt    d         3      1   \n",
      "32  g1pB_taskc.txt    c         1      1   \n",
      "33  g1pB_taskd.txt    d         2      1   \n",
      "34  g1pB_taske.txt    e         3      1   \n",
      "35  g1pD_taska.txt    a         2      1   \n",
      "36  g1pD_taskb.txt    b         3      1   \n",
      "39  g1pD_taske.txt    e         1      1   \n",
      "41  g2pA_taskb.txt    b         1      1   \n",
      "42  g2pA_taskc.txt    c         2      1   \n",
      "43  g2pA_taskd.txt    d         3      1   \n",
      "47  g2pB_taskc.txt    c         1      1   \n",
      "48  g2pB_taskd.txt    d         2      1   \n",
      "49  g2pB_taske.txt    e         3      1   \n",
      "50  g2pC_taska.txt    a         3      1   \n",
      "53  g2pC_taskd.txt    d         1      1   \n",
      "54  g2pC_taske.txt    e         2      1   \n",
      "55  g2pE_taska.txt    a         1      1   \n",
      "56  g2pE_taskb.txt    b         2      1   \n",
      "57  g2pE_taskc.txt    c         3      1   \n",
      "61  g3pA_taskb.txt    b         1      1   \n",
      "62  g3pA_taskc.txt    c         2      1   \n",
      "63  g3pA_taskd.txt    d         3      1   \n",
      "67  g3pB_taskc.txt    c         1      1   \n",
      "68  g3pB_taskd.txt    d         2      1   \n",
      "69  g3pB_taske.txt    e         3      1   \n",
      "70  g3pC_taska.txt    a         3      1   \n",
      "73  g3pC_taskd.txt    d         1      1   \n",
      "74  g3pC_taske.txt    e         2      1   \n",
      "77  g4pB_taskc.txt    c         1      1   \n",
      "78  g4pB_taskd.txt    d         2      1   \n",
      "79  g4pB_taske.txt    e         3      1   \n",
      "80  g4pC_taska.txt    a         3      1   \n",
      "83  g4pC_taskd.txt    d         1      1   \n",
      "84  g4pC_taske.txt    e         2      1   \n",
      "85  g4pD_taska.txt    a         2      1   \n",
      "86  g4pD_taskb.txt    b         3      1   \n",
      "89  g4pD_taske.txt    e         1      1   \n",
      "90  g4pE_taska.txt    a         1      1   \n",
      "91  g4pE_taskb.txt    b         2      1   \n",
      "92  g4pE_taskc.txt    c         3      1   \n",
      "\n",
      "                                                 Text  \n",
      "1   pagerank is a link analysis algorithm used by ...  \n",
      "2   the vector space model also called term vector...  \n",
      "3   bayes theorem was names after rev thomas bayes...  \n",
      "7   vector space model is an algebraic model for r...  \n",
      "8   bayes theorem relates the conditional and marg...  \n",
      "9   dynamic programming is a method for solving ma...  \n",
      "10  inheritance in object oriented programming is ...  \n",
      "13  in probability theory bayes theorem often call...  \n",
      "14  in computer science dynamic programming is a w...  \n",
      "15  inheritance in object oriented programming is ...  \n",
      "16  pagerank algorithm is patented by stanford uni...  \n",
      "17  an algebraic model for representing text docum...  \n",
      "20  in object oriented programming inheritance is ...  \n",
      "21  pagerank is a link analysis algorithm used by ...  \n",
      "24  dynamic programming is a method of solving pro...  \n",
      "26  the pagerank algorithm is used to designate ev...  \n",
      "27  the vector space model is an algebraic model u...  \n",
      "28  bayes theorem relates the conditional and marg...  \n",
      "32  the algebraic model for representing text docu...  \n",
      "33  bayes theorem relates the conditional and marg...  \n",
      "34  in mathematics and computer science dynamic pr...  \n",
      "35  inheritance is a method of forming new classes...  \n",
      "36  pagerank is a link analysis algorithm used by ...  \n",
      "39  dynamic programming is a faster method of solv...  \n",
      "41  the algorithm that google uses to assign a wei...  \n",
      "42  a vector space model or term vector model is a...  \n",
      "43   in probability theory bayes theorem often cal...  \n",
      "47  a vector space model is an algebraic model for...  \n",
      "48   in probability theory bayes theorem also call...  \n",
      "49   in mathematics and computer science dynamic p...  \n",
      "50  inheritance is a way to form new classes insta...  \n",
      "53  in probability theory bayes theorem relates th...  \n",
      "54  dynamic programming is a problem solving metho...  \n",
      "55  when we talk about inheritance in object orien...  \n",
      "56  pagerank is a link analysis algorithm that is ...  \n",
      "57  nformation retrieval ir is the science of sear...  \n",
      "61  the google search engine uses a link analysis ...  \n",
      "62  vector space model or term vector model as it ...  \n",
      "63  in probability theory bayes theorem often call...  \n",
      "67  there are a large number of models used in sol...  \n",
      "68  bayes theorem often called bayes law connects ...  \n",
      "69  dynamic programming is a method of solving pro...  \n",
      "70  in object oriented programming inheritance is ...  \n",
      "73  in probability theory the prior and conditiona...  \n",
      "74  in computer science and mathematics dynamic pr...  \n",
      "77  the vector space model or term vector model is...  \n",
      "78  in probability theory bayes theorem or bayes l...  \n",
      "79  in mathematics and computer science dynamic pr...  \n",
      "80  in object oriented programming inheritance is ...  \n",
      "83  in probability theory bayes theorem relates th...  \n",
      "84  in mathematics and computer science dynamic pr...  \n",
      "85  the idea of inheritance in oop refers to the f...  \n",
      "86  pagerank is a probability distribution used to...  \n",
      "89  dynamic programming is a method of providing s...  \n",
      "90  object oriented programming is a style of prog...  \n",
      "91  pagerankalgorithm is also known as link analys...  \n",
      "92  the definition of term depends on the applicat...  \n",
      "              File Task  Category  Class  \\\n",
      "0   g0pA_taska.txt    a         0      0   \n",
      "4   g0pA_taske.txt    e         0      0   \n",
      "5   g0pB_taska.txt    a         0      0   \n",
      "6   g0pB_taskb.txt    b         0      0   \n",
      "11  g0pC_taskb.txt    b         0      0   \n",
      "12  g0pC_taskc.txt    c         0      0   \n",
      "18  g0pD_taskd.txt    d         0      0   \n",
      "19  g0pD_taske.txt    e         0      0   \n",
      "22  g0pE_taskc.txt    c         0      0   \n",
      "23  g0pE_taskd.txt    d         0      0   \n",
      "25  g1pA_taska.txt    a         0      0   \n",
      "29  g1pA_taske.txt    e         0      0   \n",
      "30  g1pB_taska.txt    a         0      0   \n",
      "31  g1pB_taskb.txt    b         0      0   \n",
      "37  g1pD_taskc.txt    c         0      0   \n",
      "38  g1pD_taskd.txt    d         0      0   \n",
      "40  g2pA_taska.txt    a         0      0   \n",
      "44  g2pA_taske.txt    e         0      0   \n",
      "45  g2pB_taska.txt    a         0      0   \n",
      "46  g2pB_taskb.txt    b         0      0   \n",
      "51  g2pC_taskb.txt    b         0      0   \n",
      "52  g2pC_taskc.txt    c         0      0   \n",
      "58  g2pE_taskd.txt    d         0      0   \n",
      "59  g2pE_taske.txt    e         0      0   \n",
      "60  g3pA_taska.txt    a         0      0   \n",
      "64  g3pA_taske.txt    e         0      0   \n",
      "65  g3pB_taska.txt    a         0      0   \n",
      "66  g3pB_taskb.txt    b         0      0   \n",
      "71  g3pC_taskb.txt    b         0      0   \n",
      "72  g3pC_taskc.txt    c         0      0   \n",
      "75  g4pB_taska.txt    a         0      0   \n",
      "76  g4pB_taskb.txt    b         0      0   \n",
      "81  g4pC_taskb.txt    b         0      0   \n",
      "82  g4pC_taskc.txt    c         0      0   \n",
      "87  g4pD_taskc.txt    c         0      0   \n",
      "88  g4pD_taskd.txt    d         0      0   \n",
      "93  g4pE_taskd.txt    d         0      0   \n",
      "94  g4pE_taske.txt    e         0      0   \n",
      "\n",
      "                                                 Text  \n",
      "0   inheritance is a basic concept of object orien...  \n",
      "4   dynamic programming is an algorithm design tec...  \n",
      "5   inheritance is a basic concept in object orien...  \n",
      "6   pagerank pr refers to both the concept and the...  \n",
      "11  there are many attributes which infulance the ...  \n",
      "12  the vector space model is where each document ...  \n",
      "18  baye s theorm in connection with conditional p...  \n",
      "19  dynamic programming dp is an extremely powerfu...  \n",
      "22  the representation of a set of documents as ve...  \n",
      "23  bayes theorem is an important theorem relating...  \n",
      "25  in object oriented programming objects are gro...  \n",
      "29  dynamic programming is an algorithmic techniqu...  \n",
      "30  inheritance is one of the basic concepts of ob...  \n",
      "31  a websites page rank is how important it is on...  \n",
      "37  within information retrieval each document in ...  \n",
      "38  bayes theorem is a mathematical formula used t...  \n",
      "40  inheritance allows programs developed in an ob...  \n",
      "44  dynamic programming is a very powerful mathema...  \n",
      "45   inheritance is an important feature in object...  \n",
      "46  the first thing to consider when talking about...  \n",
      "51  the pagerank is a recursive algorithm used by ...  \n",
      "52  in the vector space model vsm  documents take ...  \n",
      "58  the probability of an event happening mean con...  \n",
      "59  dynamic programming dp is in basic terms an al...  \n",
      "60  in object oriented programming inheritance is ...  \n",
      "64  in the field of computer science term dynamic ...  \n",
      "65  inheritance is a concept in object oriented pr...  \n",
      "66  pagerank is an algorithm that was developed by...  \n",
      "71  the pagerank algorithm used by google harnesse...  \n",
      "72  using the vector space model for information r...  \n",
      "75  inheritance is the ability of a subclass to in...  \n",
      "76  page rank algorithm is used to determine a web...  \n",
      "81  since the develop of the web 2 0 google as one...  \n",
      "82  the vector space model are the documents which...  \n",
      "87  in vector space model the documents from which...  \n",
      "88  bayes theorem is a simple mathematical formula...  \n",
      "93   bayes theorem or bayes rule  or something cal...  \n",
      "94   dynamic programming is a method for efficient...  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "      <th>Datatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inheritance is a basic concept of object orien...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>pagerank is a link analysis algorithm used by ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>the vector space model also called term vector...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bayes theorem was names after rev thomas bayes...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dynamic programming is an algorithm design tec...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>g0pB_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inheritance is a basic concept in object orien...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g0pB_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pagerank pr refers to both the concept and the...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>g0pB_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>vector space model is an algebraic model for r...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>g0pB_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>bayes theorem relates the conditional and marg...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>g0pB_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dynamic programming is a method for solving ma...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task  Category  Class  \\\n",
       "0  g0pA_taska.txt    a         0      0   \n",
       "1  g0pA_taskb.txt    b         3      1   \n",
       "2  g0pA_taskc.txt    c         2      1   \n",
       "3  g0pA_taskd.txt    d         1      1   \n",
       "4  g0pA_taske.txt    e         0      0   \n",
       "5  g0pB_taska.txt    a         0      0   \n",
       "6  g0pB_taskb.txt    b         0      0   \n",
       "7  g0pB_taskc.txt    c         3      1   \n",
       "8  g0pB_taskd.txt    d         2      1   \n",
       "9  g0pB_taske.txt    e         1      1   \n",
       "\n",
       "                                                Text Datatype  \n",
       "0  inheritance is a basic concept of object orien...    train  \n",
       "1  pagerank is a link analysis algorithm used by ...     test  \n",
       "2  the vector space model also called term vector...    train  \n",
       "3  bayes theorem was names after rev thomas bayes...    train  \n",
       "4  dynamic programming is an algorithm design tec...    train  \n",
       "5  inheritance is a basic concept in object orien...    train  \n",
       "6  pagerank pr refers to both the concept and the...    train  \n",
       "7  vector space model is an algebraic model for r...     test  \n",
       "8  bayes theorem relates the conditional and marg...    train  \n",
       "9  dynamic programming is a method for solving ma...     test  "
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 1 # can change; set for reproducibility\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "import helpers\n",
    "\n",
    "# create new df with Datatype (train, test, orig) column\n",
    "# pass in `text_df` from above to create a complete dataframe, with all the information you need\n",
    "\"\"\"\n",
    "    # function train_test_dataframe() calls the function create_datatype()\n",
    "    # Creates test & training datatypes for plagiarized answers (1,2,3)\n",
    "    # https://docs.python.org/3/library/operator.html#module-operator\n",
    "    create_datatype(new_df, 1, 2, 'Datatype', 'Category', operator.gt, 0, 1, random_seed)\n",
    "\n",
    "    # Creates test & training datatypes for NON-plagiarized answers (0)\n",
    "    create_datatype(new_df, 1, 2, 'Datatype', 'Category', operator.eq, 0, 2, random_seed)\n",
    "\"\"\"\n",
    "\n",
    "complete_df = helpers.train_test_dataframe(text_df, random_seed=random_seed)\n",
    "\n",
    "# check results dataframe\n",
    "complete_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining Plagiarism\n",
    "\n",
    "Now that you've prepared this data and created a `complete_df` of information, including the text and class associated with each file, you can move on to the task of extracting similarity features that will be useful for plagiarism classification. \n",
    "\n",
    "> Note: The following code exercises, assume that the `complete_df` as it exists now, will **not** have its existing columns modified. \n",
    "\n",
    "The `complete_df` should always include the columns: `['File', 'Task', 'Category', 'Class', 'Text', 'Datatype']`. You can add additional columns, and you can create any new DataFrames you need by copying the parts of the `complete_df` as long as you do not modify the existing values, directly.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Similarity Features \n",
    "\n",
    "One of the ways we might go about detecting plagiarism, is by computing **similarity features** that measure how similar a given answer text is as compared to the original wikipedia source text (for a specific task, a-e). The similarity features you will use are informed by [this paper on plagiarism detection](https://s3.amazonaws.com/video.udacity-data.com/topher/2019/January/5c412841_developing-a-corpus-of-plagiarised-short-answers/developing-a-corpus-of-plagiarised-short-answers.pdf). \n",
    "> In this paper, researchers created features called **containment** and **longest common subsequence**. \n",
    "\n",
    "Using these features as input, you will train a model to distinguish between plagiarized and not-plagiarized text files.\n",
    "\n",
    "## Feature Engineering\n",
    "\n",
    "Let's talk a bit more about the features we want to include in a plagiarism detection model and how to calculate such features. In the following explanations, I'll refer to a submitted text file as a **Student Answer Text (A)** and the original, wikipedia source file (that we want to compare that answer to) as the **Wikipedia Source Text (S)**.\n",
    "\n",
    "### Containment\n",
    "\n",
    "Your first task will be to create **containment features**. To understand containment, let's first revisit a definition of [n-grams](https://en.wikipedia.org/wiki/N-gram). An *n-gram* is a sequential word grouping. For example, in a line like \"bayes rule gives us a way to combine prior knowledge with new information,\" a 1-gram is just one word, like \"bayes.\" A 2-gram might be \"bayes rule\" and a 3-gram might be \"combine prior knowledge.\"\n",
    "\n",
    "> Containment is defined as the **intersection** of the n-gram word count of the Wikipedia Source Text (S) with the n-gram word count of the Student  Answer Text (S) *divided* by the n-gram word count of the Student Answer Text.\n",
    "\n",
    "$$ \\frac{\\sum{count(\\text{ngram}_{A}) \\cap count(\\text{ngram}_{S})}}{\\sum{count(\\text{ngram}_{A})}} $$\n",
    "\n",
    "If the two texts have no n-grams in common, the containment will be 0, but if _all_ their n-grams intersect then the containment will be 1. Intuitively, you can see how having longer n-gram's in common, might be an indication of cut-and-paste plagiarism. In this project, it will be up to you to decide on the appropriate `n` or several `n`'s to use in your final model.\n",
    "\n",
    "### EXERCISE: Create containment features\n",
    "\n",
    "Given the `complete_df` that you've created, you should have all the information you need to compare any Student  Answer Text (A) with its appropriate Wikipedia Source Text (S). An answer for task A should be compared to the source text for task A, just as answers to tasks B, C, D, and E should be compared to the corresponding original source text.\n",
    "\n",
    "In this exercise, you'll complete the function, `calculate_containment` which calculates containment based upon the following parameters:\n",
    "* A given DataFrame, `df` (which is assumed to be the `complete_df` from above)\n",
    "* An `answer_filename`, such as 'g0pB_taskd.txt' \n",
    "* An n-gram length, `n`\n",
    "\n",
    "### Containment calculation\n",
    "\n",
    "The general steps to complete this function are as follows:\n",
    "1. From *all* of the text files in a given `df`, create an array of n-gram counts; it is suggested that you use a [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) for this purpose.\n",
    "2. Get the processed answer and source texts for the given `answer_filename`.\n",
    "3. Calculate the containment between an answer and source text according to the following equation.\n",
    "\n",
    "    >$$ \\frac{\\sum{count(\\text{ngram}_{A}) \\cap count(\\text{ngram}_{S})}}{\\sum{count(\\text{ngram}_{A})}} $$\n",
    "    \n",
    "4. Return that containment value.\n",
    "\n",
    "You are encouraged to write any helper functions that you need to complete the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8    bayes theorem relates the conditional and marg...\n",
      "Name: Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(text_df[text_df['File']=='g0pB_taskd.txt']['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bayes theorem relates the conditional and marginal probabilities of two random events for example a person may be seen to have certain medical symptoms bayes theorem can then be used to compute the probability that given that observation the proposed diagnosis is the right one  bayes theorem forms a relationship between the probabilities xcof events a and b intuitively bayes theorem in this form describes the way in which one s recognition of a are updated by having observed b  p a  b  p b  a p a  p b  p a b is the conditional probability of a given b it is derived from or depends upon the specified value of b therefore it is also known as the posterior probability  p b a is the conditional probability of b given a  p a is the prior probability a it doesn t take into account any information about b so it is prior  p b is the prior or marginal probability of b and acts to normalise the probability  to derive the theorem we begin with the definition of conditional probability by combining and re arranging these two equations for a and b we get a the lemma called product rule for probabilities provided that p b is not a zero dividing both sides by p b renders us with bayes theorem '"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# its associated index\n",
    "# complete_df = text_df\n",
    "# 'g0pB_taskd.txt' = answer_filename\n",
    "answer_text_index=(text_df[text_df['File']=='g0pB_taskd.txt']['Text'].index)[0] # you are getting the index value\n",
    "answer_text=(text_df[text_df['File']=='g0pB_taskd.txt']['Text'].values)[0]\n",
    "answer_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Calculate the ngram containment for one answer file/source file pair in a df\n",
    "def calculate_containment(df, n, answer_filename):\n",
    "    '''Calculates the containment between a given answer text and its associated source text.\n",
    "       This function creates a count of ngrams (of a size, n) for each text file in our data.\n",
    "       Then calculates the containment by finding the ngram count for a given answer text, \n",
    "       and its associated source text, and calculating the normalized intersection of those counts.\n",
    "       :param df: A dataframe with columns,\n",
    "           'File', 'Task', 'Category', 'Class', 'Text', and 'Datatype'\n",
    "       :param n: An integer that defines the ngram size\n",
    "       :param answer_filename: A filename for an answer text in the df, ex. 'g0pB_taskd.txt'\n",
    "       :return: A single containment value that represents the similarity\n",
    "           between an answer text and its source text.\n",
    "    '''\n",
    "    # its associated index\n",
    "    # complete_df = text_df\n",
    "    # 'g0pB_taskd.txt' = answer_filename\n",
    "    answer_text_index=(df[df['File']==answer_filename]['Text'].index)[0] # Get the index value\n",
    "    answer_text=(df[df['File']==answer_filename]['Text'].values)[0]\n",
    "    task_letter = df.loc[answer_text_index, 'Task']  # Get Corresponding \"Task\" letter from index\n",
    "    source_text = text_df.loc[(text_df.Category == -1) & (text_df.Task == task_letter),'Text'].values[0]\n",
    "    \n",
    "\n",
    "    counts = CountVectorizer(analyzer='word', ngram_range=(n,n))\n",
    "    \n",
    "    # create a dictionary of n-grams by calling `.fit`\n",
    "    vocab2int = counts.fit([answer_text, source_text]).vocabulary_\n",
    "    vocab2int\n",
    "    \n",
    "    # create array of n-gram counts for the answer and source text\n",
    "    ngrams = counts.fit_transform([answer_text, source_text])\n",
    "    #print(ngrams)\n",
    "\n",
    "    # row = the 2 texts and column = indexed vocab terms (as mapped above)\n",
    "    # ex. column 0 = 'an', col 1 = 'answer'.. col 4 = 'text'\n",
    "    ngram_array = ngrams.toarray()\n",
    "\n",
    "    intersection = sum(np.minimum(ngram_array[0,], ngram_array[1,]))\n",
    "    answer_text_count = ngram_array[0,].sum()\n",
    "    c = intersection/answer_text_count\n",
    "\n",
    "    return c\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cells\n",
    "\n",
    "After you've implemented the containment function, you can test out its behavior. \n",
    "\n",
    "The cell below iterates through the first few files, and calculates the original category _and_ containment values for a specified n and file.\n",
    "\n",
    ">If you've implemented this correctly, you should see that the non-plagiarized have low or close to 0 containment values and that plagiarized examples have higher containment values, closer to 1.\n",
    "\n",
    "Note what happens when you change the value of n. I recommend applying your code to multiple files and comparing the resultant containment values. You should see that the highest containment values correspond to files with the highest category (`cut`) of plagiarism level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "      <th>Datatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inheritance is a basic concept of object orien...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>pagerank is a link analysis algorithm used by ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>the vector space model also called term vector...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bayes theorem was names after rev thomas bayes...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dynamic programming is an algorithm design tec...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>g0pB_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inheritance is a basic concept in object orien...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g0pB_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pagerank pr refers to both the concept and the...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>g0pB_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>vector space model is an algebraic model for r...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>g0pB_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>bayes theorem relates the conditional and marg...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>g0pB_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dynamic programming is a method for solving ma...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task  Category  Class  \\\n",
       "0  g0pA_taska.txt    a         0      0   \n",
       "1  g0pA_taskb.txt    b         3      1   \n",
       "2  g0pA_taskc.txt    c         2      1   \n",
       "3  g0pA_taskd.txt    d         1      1   \n",
       "4  g0pA_taske.txt    e         0      0   \n",
       "5  g0pB_taska.txt    a         0      0   \n",
       "6  g0pB_taskb.txt    b         0      0   \n",
       "7  g0pB_taskc.txt    c         3      1   \n",
       "8  g0pB_taskd.txt    d         2      1   \n",
       "9  g0pB_taske.txt    e         1      1   \n",
       "\n",
       "                                                Text Datatype  \n",
       "0  inheritance is a basic concept of object orien...    train  \n",
       "1  pagerank is a link analysis algorithm used by ...     test  \n",
       "2  the vector space model also called term vector...    train  \n",
       "3  bayes theorem was names after rev thomas bayes...    train  \n",
       "4  dynamic programming is an algorithm design tec...    train  \n",
       "5  inheritance is a basic concept in object orien...    train  \n",
       "6  pagerank pr refers to both the concept and the...    train  \n",
       "7  vector space model is an algebraic model for r...     test  \n",
       "8  bayes theorem relates the conditional and marg...    train  \n",
       "9  dynamic programming is a method for solving ma...     test  "
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df.head(10) # Shape (100,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original category values: \n",
      " [0, 3, 2, 1, 0]\n",
      "\n",
      "3-gram containment values: \n",
      " [0.009345794392523364, 0.9641025641025641, 0.6136363636363636, 0.15675675675675677, 0.031746031746031744]\n"
     ]
    }
   ],
   "source": [
    "# select a value for n\n",
    "n = 3\n",
    "\n",
    "# This function is what i am calling\n",
    "# def calculate_containment(df, n, answer_filename):\n",
    "\n",
    "# indices for first few files\n",
    "test_indices = range(5)\n",
    "\n",
    "\n",
    "# iterate through files and calculate containment\n",
    "# This is where the iteration happens\n",
    "category_vals = []\n",
    "containment_vals = []\n",
    "for i in test_indices:\n",
    "\n",
    "    #print(complete_df.loc[i, 'Category'])\n",
    "    # get level of plagiarism for a given file index\n",
    "    category_vals.append(complete_df.loc[i, 'Category'])\n",
    "    #print('category_vals',category_vals)\n",
    "    # calculate containment for given file and n\n",
    "    filename = complete_df.loc[i, 'File']\n",
    "    #print(filename)\n",
    "    c = calculate_containment(complete_df, n, filename)\n",
    "    containment_vals.append(c)\n",
    "    #print('containment_vals',containment_vals)\n",
    "\n",
    "# print out result, does it make sense?\n",
    "print('Original category values: \\n', category_vals)\n",
    "print()\n",
    "print(str(n)+'-gram containment values: \\n', containment_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed!\n"
     ]
    }
   ],
   "source": [
    "# run this test cell\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# test containment calculation\n",
    "# params: complete_df from before, and containment function\n",
    "tests.test_containment(complete_df, calculate_containment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 1: Why can we calculate containment features across *all* data (training & test), prior to splitting the DataFrame for modeling? That is, what about the containment calculation means that the test and training data do not influence each other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "The containment features is across all data and it is prior to the train/test split. We select the features, and it should not influence the train/ test data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Longest Common Subsequence\n",
    "\n",
    "Containment a good way to find overlap in word usage between two documents; it may help identify cases of cut-and-paste as well as paraphrased levels of plagiarism. Since plagiarism is a fairly complex task with varying levels, it's often useful to include other measures of similarity. The paper also discusses a feature called **longest common subsequence**.\n",
    "\n",
    "> The longest common subsequence is the longest string of words (or letters) that are *the same* between the Wikipedia Source Text (S) and the Student Answer Text (A). This value is also normalized by dividing by the total number of words (or letters) in the  Student Answer Text. \n",
    "\n",
    "In this exercise, we'll ask you to calculate the longest common subsequence of words between two texts.\n",
    "\n",
    "### EXERCISE: Calculate the longest common subsequence\n",
    "\n",
    "Complete the function `lcs_norm_word`; this should calculate the *longest common subsequence* of words between a Student Answer Text and corresponding Wikipedia Source Text. \n",
    "\n",
    "It may be helpful to think of this in a concrete example. A Longest Common Subsequence (LCS) problem may look as follows:\n",
    "* Given two texts: text A (answer text) of length n, and string S (original source text) of length m. Our goal is to produce their longest common subsequence of words: the longest sequence of words that appear left-to-right in both texts (though the words don't have to be in continuous order).\n",
    "* Consider:\n",
    "    * A = \"i think pagerank is a link analysis algorithm used by google that uses a system of weights attached to each element of a hyperlinked set of documents\"\n",
    "    * S = \"pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents\"\n",
    "\n",
    "* In this case, we can see that the start of each sentence of fairly similar, having overlap in the sequence of words, \"pagerank is a link analysis algorithm used by\" before diverging slightly. Then we **continue moving left -to-right along both texts** until we see the next common sequence; in this case it is only one word, \"google\". Next we find \"that\" and \"a\" and finally the same ending \"to each element of a hyperlinked set of documents\".\n",
    "* Below, is a clear visual of how these sequences were found, sequentially, in each text.\n",
    "\n",
    "<img src='notebook_ims/common_subseq_words.png' width=40% />\n",
    "\n",
    "* Now, those words appear in left-to-right order in each document, sequentially, and even though there are some words in between, we count this as the longest common subsequence between the two texts. \n",
    "* If I count up each word that I found in common I get the value 20. **So, LCS has length 20**. \n",
    "* Next, to normalize this value, divide by the total length of the student answer; in this example that length is only 27. **So, the function `lcs_norm_word` should return the value `20/27` or about `0.7408`.**\n",
    "\n",
    "In this way, LCS is a great indicator of cut-and-paste plagiarism or if someone has referenced the same source text multiple times in an answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCS, dynamic programming\n",
    "\n",
    "If you read through the scenario above, you can see that this algorithm depends on looking at two texts and comparing them word by word. You can solve this problem in multiple ways. First, it may be useful to `.split()` each text into lists of comma separated words to compare. Then, you can iterate through each word in the texts and compare them, adding to your value for LCS as you go. \n",
    "\n",
    "The method I recommend for implementing an efficient LCS algorithm is: using a matrix and dynamic programming. **Dynamic programming** is all about breaking a larger problem into a smaller set of subproblems, and building up a complete result without having to repeat any subproblems. \n",
    "\n",
    "This approach assumes that you can split up a large LCS task into a combination of smaller LCS tasks. Let's look at a simple example that compares letters:\n",
    "\n",
    "* A = \"ABCD\"\n",
    "* S = \"BD\"\n",
    "\n",
    "We can see right away that the longest subsequence of _letters_ here is 2 (B and D are in sequence in both strings). And we can calculate this by looking at relationships between each letter in the two strings, A and S.\n",
    "\n",
    "Here, I have a matrix with the letters of A on top and the letters of S on the left side:\n",
    "\n",
    "<img src='notebook_ims/matrix_1.png' width=40% />\n",
    "\n",
    "This starts out as a matrix that has as many columns and rows as letters in the strings S and O **+1** additional row and column, filled with zeros on the top and left sides. So, in this case, instead of a 2x4 matrix it is a 3x5.\n",
    "\n",
    "Now, we can fill this matrix up by breaking it into smaller LCS problems. For example, let's first look at the shortest substrings: the starting letter of A and S. We'll first ask, what is the Longest Common Subsequence between these two letters \"A\" and \"B\"? \n",
    "\n",
    "**Here, the answer is zero and we fill in the corresponding grid cell with that value.**\n",
    "\n",
    "<img src='notebook_ims/matrix_2.png' width=30% />\n",
    "\n",
    "Then, we ask the next question, what is the LCS between \"AB\" and \"B\"?\n",
    "\n",
    "**Here, we have a match, and can fill in the appropriate value 1**.\n",
    "\n",
    "<img src='notebook_ims/matrix_3_match.png' width=25% />\n",
    "\n",
    "If we continue, we get to a final matrix that looks as follows, with a **2** in the bottom right corner.\n",
    "\n",
    "<img src='notebook_ims/matrix_6_complete.png' width=25% />\n",
    "\n",
    "The final LCS will be that value **2** *normalized* by the number of n-grams in A. So, our normalized value is 2/4 = **0.5**.\n",
    "\n",
    "### The matrix rules\n",
    "\n",
    "One thing to notice here is that, you can efficiently fill up this matrix one cell at a time. Each grid cell only depends on the values in the grid cells that are directly on top and to the left of it, or on the diagonal/top-left. The rules are as follows:\n",
    "* Start with a matrix that has one extra row and column of zeros.\n",
    "* As you traverse your string:\n",
    "    * If there is a match, fill that grid cell with the value to the top-left of that cell *plus* one. So, in our case, when we found a matching B-B, we added +1 to the value in the top-left of the matching cell, 0.\n",
    "    * If there is not a match, take the *maximum* value from either directly to the left or the top cell, and carry that value over to the non-match cell.\n",
    "\n",
    "<img src='notebook_ims/matrix_rules.png' width=50% />\n",
    "\n",
    "After completely filling the matrix, **the bottom-right cell will hold the non-normalized LCS value**.\n",
    "\n",
    "This matrix treatment can be applied to a set of words instead of letters. Your function should apply this to the words in two texts and return the normalized LCS value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcs_norm_word(answer_text, source_text):  # LCS LongestCommonSubsequence\n",
    "    \n",
    "\n",
    "    n = answer_text.split() # This is the answer_text all words\n",
    "    m = source_text.split() # This is the source_text all words\n",
    "    word_list_n = len(n)\n",
    "    word_list_m = len(m)\n",
    "    \n",
    "    rows, cols = (word_list_n+1, word_list_m+1)\n",
    "    # Creates a nested loop, of length str1+1 and length str2+1\n",
    "    dp = [[0 for i in range(cols)] for j in range(rows)] # Inner list i, columns+1\n",
    "                                                         # outer list j, rows+1\n",
    "#    \n",
    "    for i in range(word_list_n+1):# column string\n",
    "        for j in range(word_list_m+1):# row string \n",
    "        # Get the last word of each string in this case 'documents'\n",
    "            answer_lastword = n[i-1]\n",
    "            source_lastword = m[j-1]\n",
    "    \n",
    "            if i == 0 or j == 0: # Return the recursive calls\n",
    "                dp[i][j]=0\n",
    "            elif answer_lastword == source_lastword:  # Match\n",
    "                dp[i][j] = 1+dp[i-1][j-1]\n",
    "            else: #no match\n",
    "                dp[i][j] = max(dp[i-1][j],dp[i][j-1])\n",
    "\n",
    "                \n",
    "    lcs = ((dp[word_list_n][word_list_m])/word_list_n)         \n",
    "#    print(dp[word_list_n][word_list_m],word_list_n)       \n",
    "\n",
    "\n",
    "    return lcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cells\n",
    "\n",
    "Let's start by testing out your code on the example given in the initial description.\n",
    "\n",
    "In the below cell, we have specified strings A (answer text) and S (original source text). We know that these texts have 20 words in common and the submitted answer is 27 words long, so the normalized, longest common subsequence should be 20/27.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCS =  0.7407407407407407\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# Run the test scenario from above\n",
    "# does your function return the expected value?\n",
    "\n",
    "A = \"i think pagerank is a link analysis algorithm used by google that uses a system of weights attached to each element of a hyperlinked set of documents\"\n",
    "S = \"pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents\"\n",
    "\n",
    "# calculate LCS\n",
    "lcs = lcs_norm_word(A, S)\n",
    "print('LCS = ', lcs)\n",
    "\n",
    "\n",
    "# expected value test\n",
    "assert lcs==20/27., \"Incorrect LCS value, expected about 0.7408, got \"+str(lcs)\n",
    "\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell runs a more rigorous test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed!\n"
     ]
    }
   ],
   "source": [
    "# run test cell\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# test lcs implementation\n",
    "# params: complete_df from before, and lcs_norm_word function\n",
    "tests.test_lcs(complete_df, lcs_norm_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, take a look at a few resultant values for `lcs_norm_word`. Just like before, you should see that higher values correspond to higher levels of plagiarism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original category values: \n",
      " [0, 3, 2, 1, 0]\n",
      "\n",
      "Normalized LCS values: \n",
      " [0.1917808219178082, 0.8207547169811321, 0.8464912280701754, 0.3160621761658031, 0.24257425742574257]\n"
     ]
    }
   ],
   "source": [
    "# test on your own\n",
    "test_indices = range(5) # look at first few files\n",
    "\n",
    "category_vals = []\n",
    "lcs_norm_vals = []\n",
    "# iterate through first few docs and calculate LCS\n",
    "for i in test_indices:\n",
    "    category_vals.append(complete_df.loc[i, 'Category'])\n",
    "    # get texts to compare\n",
    "    answer_text = complete_df.loc[i, 'Text'] # From each i location get texts\n",
    "    task = complete_df.loc[i, 'Task'] # From each i location get task letter\n",
    "    # we know that source texts have Class = -1\n",
    "    orig_rows = complete_df[(complete_df['Class'] == -1)] # A dataframe list of all ASource texts of class -1\n",
    "    orig_row = orig_rows[(orig_rows['Task'] == task)] # All source texts of -1 find all tasks == 'd'\n",
    "    source_text = orig_row['Text'].values[0]  # Get source texti string at task == 'd'\n",
    "    \n",
    "    # calculate lcs\n",
    "    lcs_val = lcs_norm_word(answer_text, source_text)\n",
    "    lcs_norm_vals.append(lcs_val)\n",
    "\n",
    "# print out result, does it make sense?\n",
    "print('Original category values: \\n', category_vals)\n",
    "print()\n",
    "print('Normalized LCS values: \\n', lcs_norm_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Create All Features\n",
    "\n",
    "Now that you've completed the feature calculation functions, it's time to actually create multiple features and decide on which ones to use in your final model! In the below cells, you're provided two helper functions to help you create multiple features and store those in a DataFrame, `features_df`.\n",
    "\n",
    "### Creating multiple containment features\n",
    "\n",
    "Your completed `calculate_containment` function will be called in the next cell, which defines the helper function `create_containment_features`. \n",
    "\n",
    "> This function returns a list of containment features, calculated for a given `n` and for *all* files in a df (assumed to the the `complete_df`).\n",
    "\n",
    "For our original files, the containment value is set to a special value, -1.\n",
    "\n",
    "This function gives you the ability to easily create several containment features, of different n-gram lengths, for each of our text files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Overview Features\n",
    "In this project, you will be tasked with building a plagiarism detector that examines a text file and performs binary \n",
    "classification; labeling that file as either plagiarized or not, depending on how similar the text file is to a \n",
    "provided source text.\n",
    "\n",
    "Feature Engineering\n",
    "\n",
    "Clean and pre-process the text data.\n",
    "Define features for comparing the similarity of an answer text and a source text, and extract similarity features.\n",
    "Select \"good\" features, by analyzing the correlations between different features.\n",
    "Create train/test .csv files that hold the relevant features and class labels for train/test data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# Function returns a list of containment features, calculated for a given n \n",
    "# Should return a list of length 100 for all files in a complete_df\n",
    "def create_containment_features(df, n, column_name=None):\n",
    "    \n",
    "    containment_values = []\n",
    "    \n",
    "    if(column_name==None):\n",
    "        column_name = 'c_'+str(n) # c_1, c_2, .. c_n\n",
    "    \n",
    "    # iterates through dataframe rows\n",
    "    for i in df.index:\n",
    "        file = df.loc[i, 'File']\n",
    "      #  print(file)\n",
    "        # Computes features using calculate_containment function\n",
    "        if df.loc[i,'Category'] > -1:\n",
    "            c = calculate_containment(df, n, file)\n",
    "            containment_values.append(c)\n",
    "        # Sets value to -1 for original tasks \n",
    "        else:\n",
    "            containment_values.append(-1)\n",
    "    \n",
    "    print(str(n)+'-gram containment features created!')\n",
    "    return containment_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating LCS features\n",
    "\n",
    "Below, your complete `lcs_norm_word` function is used to create a list of LCS features for all the answer files in a given DataFrame (again, this assumes you are passing in the `complete_df`. It assigns a special value for our original, source files, -1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# Function creates lcs feature and add it to the dataframe\n",
    "def create_lcs_features(df, column_name='lcs_word'):\n",
    "    \n",
    "    lcs_values = []\n",
    "    \n",
    "    # iterate through files in dataframe\n",
    "    for i in df.index:\n",
    "        # Computes LCS_norm words feature using function above for answer tasks\n",
    "        if df.loc[i,'Category'] > -1:\n",
    "            # get texts to compare\n",
    "            answer_text = df.loc[i, 'Text'] \n",
    "            task = df.loc[i, 'Task']\n",
    "            # we know that source texts have Class = -1\n",
    "            orig_rows = df[(df['Class'] == -1)]\n",
    "            orig_row = orig_rows[(orig_rows['Task'] == task)]\n",
    "            source_text = orig_row['Text'].values[0]\n",
    "\n",
    "            # calculate lcs\n",
    "            lcs = lcs_norm_word(answer_text, source_text)\n",
    "            lcs_values.append(lcs)\n",
    "        # Sets to -1 for original tasks \n",
    "        else:\n",
    "            lcs_values.append(-1)\n",
    "\n",
    "    print('LCS features created!')\n",
    "    return lcs_values\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE: Create a features DataFrame by selecting an `ngram_range`\n",
    "\n",
    "The paper suggests calculating the following features: containment *1-gram to 5-gram* and *longest common subsequence*. \n",
    "> In this exercise, you can choose to create even more features, for example from *1-gram to 7-gram* containment features and *longest common subsequence*. \n",
    "\n",
    "You'll want to create at least 6 features to choose from as you think about which to give to your final, classification model. Defining and comparing at least 6 different features allows you to discard any features that seem redundant, and choose to use the best features for your final model!\n",
    "\n",
    "In the below cell **define an n-gram range**; these will be the n's you use to create n-gram containment features. The rest of the feature creation code is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram containment features created!\n",
      "2-gram containment features created!\n",
      "3-gram containment features created!\n",
      "4-gram containment features created!\n",
      "5-gram containment features created!\n",
      "6-gram containment features created!\n",
      "LCS features created!\n",
      "\n",
      "Features:  ['c_1', 'c_2', 'c_3', 'c_4', 'c_5', 'c_6', 'lcs_word']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define an ngram range\n",
    "ngram_range = range(1,7)\n",
    "\n",
    "\n",
    "# The following code may take a minute to run, depending on your ngram_range\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "features_list = []\n",
    "\n",
    "# Create features in a features_df\n",
    "all_features = np.zeros((len(ngram_range)+1, len(complete_df)))\n",
    "\n",
    "# Calculate features for containment for ngrams in range\n",
    "i=0\n",
    "for n in ngram_range:\n",
    "    column_name = 'c_'+str(n)\n",
    "    features_list.append(column_name)\n",
    "    # create containment features\n",
    "    all_features[i]=np.squeeze(create_containment_features(complete_df, n))\n",
    "    i+=1\n",
    "\n",
    "# Calculate features for LCS_Norm Words \n",
    "features_list.append('lcs_word')\n",
    "all_features[i]= np.squeeze(create_lcs_features(complete_df))\n",
    "\n",
    "# create a features dataframe\n",
    "features_df = pd.DataFrame(np.transpose(all_features), columns=features_list)\n",
    "\n",
    "# Print all features/columns\n",
    "print()\n",
    "print('Features: ', features_list)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_6</th>\n",
       "      <th>lcs_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.398148</td>\n",
       "      <td>0.079070</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984694</td>\n",
       "      <td>0.964103</td>\n",
       "      <td>0.943299</td>\n",
       "      <td>0.922280</td>\n",
       "      <td>0.901042</td>\n",
       "      <td>0.820755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.869369</td>\n",
       "      <td>0.719457</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.515982</td>\n",
       "      <td>0.449541</td>\n",
       "      <td>0.382488</td>\n",
       "      <td>0.846491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.593583</td>\n",
       "      <td>0.268817</td>\n",
       "      <td>0.156757</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.060440</td>\n",
       "      <td>0.316062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.544503</td>\n",
       "      <td>0.115789</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.005319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.329502</td>\n",
       "      <td>0.053846</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.590308</td>\n",
       "      <td>0.150442</td>\n",
       "      <td>0.035556</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.765306</td>\n",
       "      <td>0.709898</td>\n",
       "      <td>0.664384</td>\n",
       "      <td>0.625430</td>\n",
       "      <td>0.589655</td>\n",
       "      <td>0.553633</td>\n",
       "      <td>0.621711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.759777</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.395480</td>\n",
       "      <td>0.306818</td>\n",
       "      <td>0.245714</td>\n",
       "      <td>0.195402</td>\n",
       "      <td>0.484305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.884444</td>\n",
       "      <td>0.526786</td>\n",
       "      <td>0.340807</td>\n",
       "      <td>0.247748</td>\n",
       "      <td>0.180995</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.597458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        c_1       c_2       c_3       c_4       c_5       c_6  lcs_word\n",
       "0  0.398148  0.079070  0.009346  0.000000  0.000000  0.000000  0.191781\n",
       "1  1.000000  0.984694  0.964103  0.943299  0.922280  0.901042  0.820755\n",
       "2  0.869369  0.719457  0.613636  0.515982  0.449541  0.382488  0.846491\n",
       "3  0.593583  0.268817  0.156757  0.108696  0.081967  0.060440  0.316062\n",
       "4  0.544503  0.115789  0.031746  0.005319  0.000000  0.000000  0.242574\n",
       "5  0.329502  0.053846  0.007722  0.003876  0.000000  0.000000  0.161172\n",
       "6  0.590308  0.150442  0.035556  0.004464  0.000000  0.000000  0.301653\n",
       "7  0.765306  0.709898  0.664384  0.625430  0.589655  0.553633  0.621711\n",
       "8  0.759777  0.505618  0.395480  0.306818  0.245714  0.195402  0.484305\n",
       "9  0.884444  0.526786  0.340807  0.247748  0.180995  0.150000  0.597458"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print some results \n",
    "features_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 7)"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlated Features\n",
    "\n",
    "You should use feature correlation across the *entire* dataset to determine which features are ***too*** **highly-correlated** with each other to include both features in a single model. For this analysis, you can use the *entire* dataset due to the small sample size we have. \n",
    "\n",
    "All of our features try to measure the similarity between two texts. Since our features are designed to measure similarity, it is expected that these features will be highly-correlated. Many classification models, for example a Naive Bayes classifier, rely on the assumption that features are *not* highly correlated; highly-correlated features may over-inflate the importance of a single feature. \n",
    "\n",
    "So, you'll want to choose your features based on which pairings have the lowest correlation. These correlation values range between 0 and 1; from low to high correlation, and are displayed in a [correlation matrix](https://www.displayr.com/what-is-a-correlation-matrix/), below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_6</th>\n",
       "      <th>lcs_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c_1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_2</th>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_3</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_4</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_5</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_6</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcs_word</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           c_1   c_2   c_3   c_4   c_5   c_6  lcs_word\n",
       "c_1       1.00  0.94  0.90  0.89  0.88  0.87      0.97\n",
       "c_2       0.94  1.00  0.99  0.98  0.97  0.96      0.98\n",
       "c_3       0.90  0.99  1.00  1.00  0.99  0.98      0.97\n",
       "c_4       0.89  0.98  1.00  1.00  1.00  0.99      0.95\n",
       "c_5       0.88  0.97  0.99  1.00  1.00  1.00      0.95\n",
       "c_6       0.87  0.96  0.98  0.99  1.00  1.00      0.94\n",
       "lcs_word  0.97  0.98  0.97  0.95  0.95  0.94      1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# Create correlation matrix for just Features to determine different models to test\n",
    "corr_matrix = features_df.corr().abs().round(2)\n",
    "\n",
    "# display shows all of a dataframe\n",
    "display(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> (7, 7)\n"
     ]
    }
   ],
   "source": [
    "print(type(corr_matrix),corr_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using Seaborn to plot correlation matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(corr_matrix, annot = True, cmap = 'coolwarm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(corr_matrix.shape[0],) # 7 elements, one row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice at threshold of 1.0 on right side, we need features that are not significant\n",
    "# I looked at https://www.youtube.com/watch?v=UgtjatBt3vY to help find my selection values\n",
    "\n",
    "threshold = 1.0\n",
    "columns = np.full((corr_matrix.shape[0],),True,dtype=bool) # shape is first position: corr_matrix.shape[0], Fill values to True\n",
    "\n",
    "columns # These are ALL TRUE CELL VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False False False  True  True] <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['c_1', 'c_2', 'c_6', 'lcs_word']"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = []  \n",
    "threshold = 1.0\n",
    "for i in range(len(columns)):\n",
    "    for j in range(i):\n",
    "        if corr_matrix.iloc[i, j] >= threshold: # and (corr_matrix.columns[j] not in col_corr):\n",
    "            if columns[j]:\n",
    "                columns[j] = False\n",
    "print(columns,type(columns))\n",
    "selected_features = features_df.columns[columns].to_list() # Place all True values in New Selected_features\n",
    "selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "      <th>Datatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inheritance is a basic concept of object orien...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>pagerank is a link analysis algorithm used by ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>the vector space model also called term vector...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bayes theorem was names after rev thomas bayes...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dynamic programming is an algorithm design tec...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task  Category  Class  \\\n",
       "0  g0pA_taska.txt    a         0      0   \n",
       "1  g0pA_taskb.txt    b         3      1   \n",
       "2  g0pA_taskc.txt    c         2      1   \n",
       "3  g0pA_taskd.txt    d         1      1   \n",
       "4  g0pA_taske.txt    e         0      0   \n",
       "\n",
       "                                                Text Datatype  \n",
       "0  inheritance is a basic concept of object orien...    train  \n",
       "1  pagerank is a link analysis algorithm used by ...     test  \n",
       "2  the vector space model also called term vector...    train  \n",
       "3  bayes theorem was names after rev thomas bayes...    train  \n",
       "4  dynamic programming is an algorithm design tec...    train  "
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df.head() #(100,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_6</th>\n",
       "      <th>lcs_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.398148</td>\n",
       "      <td>0.079070</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984694</td>\n",
       "      <td>0.964103</td>\n",
       "      <td>0.943299</td>\n",
       "      <td>0.922280</td>\n",
       "      <td>0.901042</td>\n",
       "      <td>0.820755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.869369</td>\n",
       "      <td>0.719457</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.515982</td>\n",
       "      <td>0.449541</td>\n",
       "      <td>0.382488</td>\n",
       "      <td>0.846491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.593583</td>\n",
       "      <td>0.268817</td>\n",
       "      <td>0.156757</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.060440</td>\n",
       "      <td>0.316062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.544503</td>\n",
       "      <td>0.115789</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.005319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         c_1       c_2       c_3       c_4       c_5       c_6  lcs_word\n",
       "0   0.398148  0.079070  0.009346  0.000000  0.000000  0.000000  0.191781\n",
       "1   1.000000  0.984694  0.964103  0.943299  0.922280  0.901042  0.820755\n",
       "2   0.869369  0.719457  0.613636  0.515982  0.449541  0.382488  0.846491\n",
       "3   0.593583  0.268817  0.156757  0.108696  0.081967  0.060440  0.316062\n",
       "4   0.544503  0.115789  0.031746  0.005319  0.000000  0.000000  0.242574\n",
       "..       ...       ...       ...       ...       ...       ...       ...\n",
       "95 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000\n",
       "96 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000\n",
       "97 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000\n",
       "98 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000\n",
       "99 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000\n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df # (100,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE: Create selected train/test data\n",
    "\n",
    "Complete the `train_test_data` function below. This function should take in the following parameters:\n",
    "* `complete_df`: A DataFrame that contains all of our processed text data, file info, datatypes, and class labels\n",
    "* `features_df`: A DataFrame of all calculated features, such as containment for ngrams, n= 1-5, and lcs values for each text file listed in the `complete_df` (this was created in the above cells)\n",
    "* `selected_features`: A list of feature column names,  ex. `['c_1', 'lcs_word']`, which will be used to select the final features in creating train/test sets of data.\n",
    "\n",
    "It should return two tuples:\n",
    "* `(train_x, train_y)`, selected training features and their corresponding class labels (0/1)\n",
    "* `(test_x, test_y)`, selected training features and their corresponding class labels (0/1)\n",
    "\n",
    "** Note: x and y should be arrays of feature values and numerical class labels, respectively; not DataFrames.**\n",
    "\n",
    "Looking at the above correlation matrix, you should decide on a **cutoff** correlation value, less than 1.0, to determine which sets of features are *too* highly-correlated to be included in the final training and test data. If you cannot find features that are less correlated than some cutoff value, it is suggested that you increase the number of features (longer n-grams) to choose from or use *only one or two* features in your final model to avoid introducing highly-correlated features.\n",
    "\n",
    "Recall that the `complete_df` has a `Datatype` column that indicates whether data should be `train` or `test` data; this should help you split the data appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "      <th>Datatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inheritance is a basic concept of object orien...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>the vector space model also called term vector...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bayes theorem was names after rev thomas bayes...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dynamic programming is an algorithm design tec...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>g0pB_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inheritance is a basic concept in object orien...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>g4pD_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dynamic programming is a method of providing s...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>g4pE_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>object oriented programming is a style of prog...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>g4pE_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>pagerankalgorithm is also known as link analys...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>g4pE_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>the definition of term depends on the applicat...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>g4pE_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bayes theorem or bayes rule  or something cal...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              File Task  Category  Class  \\\n",
       "0   g0pA_taska.txt    a         0      0   \n",
       "2   g0pA_taskc.txt    c         2      1   \n",
       "3   g0pA_taskd.txt    d         1      1   \n",
       "4   g0pA_taske.txt    e         0      0   \n",
       "5   g0pB_taska.txt    a         0      0   \n",
       "..             ...  ...       ...    ...   \n",
       "89  g4pD_taske.txt    e         1      1   \n",
       "90  g4pE_taska.txt    a         1      1   \n",
       "91  g4pE_taskb.txt    b         2      1   \n",
       "92  g4pE_taskc.txt    c         3      1   \n",
       "93  g4pE_taskd.txt    d         0      0   \n",
       "\n",
       "                                                 Text Datatype  \n",
       "0   inheritance is a basic concept of object orien...    train  \n",
       "2   the vector space model also called term vector...    train  \n",
       "3   bayes theorem was names after rev thomas bayes...    train  \n",
       "4   dynamic programming is an algorithm design tec...    train  \n",
       "5   inheritance is a basic concept in object orien...    train  \n",
       "..                                                ...      ...  \n",
       "89  dynamic programming is a method of providing s...    train  \n",
       "90  object oriented programming is a style of prog...    train  \n",
       "91  pagerankalgorithm is also known as link analys...    train  \n",
       "92  the definition of term depends on the applicat...    train  \n",
       "93   bayes theorem or bayes rule  or something cal...    train  \n",
       "\n",
       "[70 rows x 6 columns]"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x=complete_df[complete_df['Datatype']=='train']\n",
    "train_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "      <th>Datatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>pagerank is a link analysis algorithm used by ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>g0pB_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "      <td>vector space model is an algebraic model for r...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>g0pB_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>dynamic programming is a method for solving ma...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>g0pC_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>inheritance in object oriented programming is ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>g0pD_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>pagerank algorithm is patented by stanford uni...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>g0pE_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>in object oriented programming inheritance is ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>g0pE_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>0</td>\n",
       "      <td>bayes theorem is an important theorem relating...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>g1pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>in object oriented programming objects are gro...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>g1pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>dynamic programming is an algorithmic techniqu...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>g1pB_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>a websites page rank is how important it is on...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>g1pD_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>0</td>\n",
       "      <td>within information retrieval each document in ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>g1pD_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>0</td>\n",
       "      <td>bayes theorem is a mathematical formula used t...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>g2pB_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "      <td>a vector space model is an algebraic model for...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>g2pB_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>2</td>\n",
       "      <td>in probability theory bayes theorem also call...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>g2pB_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>3</td>\n",
       "      <td>in mathematics and computer science dynamic p...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>g3pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>the google search engine uses a link analysis ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>g3pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>vector space model or term vector model as it ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>g3pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>3</td>\n",
       "      <td>in probability theory bayes theorem often call...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>g4pB_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>inheritance is the ability of a subclass to in...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>g4pC_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "      <td>in object oriented programming inheritance is ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>g4pC_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>since the develop of the web 2 0 google as one...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>g4pC_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>in probability theory bayes theorem relates th...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>g4pC_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>2</td>\n",
       "      <td>in mathematics and computer science dynamic pr...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>g4pD_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>0</td>\n",
       "      <td>in vector space model the documents from which...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>g4pE_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>dynamic programming is a method for efficient...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              File Task  Category  \\\n",
       "1   g0pA_taskb.txt    b         3   \n",
       "7   g0pB_taskc.txt    c         3   \n",
       "9   g0pB_taske.txt    e         1   \n",
       "10  g0pC_taska.txt    a         1   \n",
       "16  g0pD_taskb.txt    b         2   \n",
       "20  g0pE_taska.txt    a         2   \n",
       "23  g0pE_taskd.txt    d         0   \n",
       "25  g1pA_taska.txt    a         0   \n",
       "29  g1pA_taske.txt    e         0   \n",
       "31  g1pB_taskb.txt    b         0   \n",
       "37  g1pD_taskc.txt    c         0   \n",
       "38  g1pD_taskd.txt    d         0   \n",
       "47  g2pB_taskc.txt    c         1   \n",
       "48  g2pB_taskd.txt    d         2   \n",
       "49  g2pB_taske.txt    e         3   \n",
       "61  g3pA_taskb.txt    b         1   \n",
       "62  g3pA_taskc.txt    c         2   \n",
       "63  g3pA_taskd.txt    d         3   \n",
       "75  g4pB_taska.txt    a         0   \n",
       "80  g4pC_taska.txt    a         3   \n",
       "81  g4pC_taskb.txt    b         0   \n",
       "83  g4pC_taskd.txt    d         1   \n",
       "84  g4pC_taske.txt    e         2   \n",
       "87  g4pD_taskc.txt    c         0   \n",
       "94  g4pE_taske.txt    e         0   \n",
       "\n",
       "                                                 Text Datatype  \n",
       "1   pagerank is a link analysis algorithm used by ...     test  \n",
       "7   vector space model is an algebraic model for r...     test  \n",
       "9   dynamic programming is a method for solving ma...     test  \n",
       "10  inheritance in object oriented programming is ...     test  \n",
       "16  pagerank algorithm is patented by stanford uni...     test  \n",
       "20  in object oriented programming inheritance is ...     test  \n",
       "23  bayes theorem is an important theorem relating...     test  \n",
       "25  in object oriented programming objects are gro...     test  \n",
       "29  dynamic programming is an algorithmic techniqu...     test  \n",
       "31  a websites page rank is how important it is on...     test  \n",
       "37  within information retrieval each document in ...     test  \n",
       "38  bayes theorem is a mathematical formula used t...     test  \n",
       "47  a vector space model is an algebraic model for...     test  \n",
       "48   in probability theory bayes theorem also call...     test  \n",
       "49   in mathematics and computer science dynamic p...     test  \n",
       "61  the google search engine uses a link analysis ...     test  \n",
       "62  vector space model or term vector model as it ...     test  \n",
       "63  in probability theory bayes theorem often call...     test  \n",
       "75  inheritance is the ability of a subclass to in...     test  \n",
       "80  in object oriented programming inheritance is ...     test  \n",
       "81  since the develop of the web 2 0 google as one...     test  \n",
       "83  in probability theory bayes theorem relates th...     test  \n",
       "84  in mathematics and computer science dynamic pr...     test  \n",
       "87  in vector space model the documents from which...     test  \n",
       "94   dynamic programming is a method for efficient...     test  "
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x=complete_df[complete_df['Datatype']=='test'].drop(['Class'],axis=1)\n",
    "test_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Deploy Your Model in SageMaker\n",
    "\n",
    "Upload your train/test feature data to S3.\n",
    "Define a binary classification model and a training script.\n",
    "Train your model and deploy it using SageMaker.\n",
    "Evaluate your deployed classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in dataframes and a list of selected features (column names) \n",
    "# and returns (train_x, train_y), (test_x, test_y)\n",
    "def train_test_data(complete_df, features_df, selected_features):\n",
    "    '''Gets selected training and test features from given dataframes, and \n",
    "       returns tuples for training and test features and their corresponding class labels.\n",
    "       :param complete_df: A dataframe with all of our processed text data, datatypes, and labels\n",
    "       :param features_df: A dataframe of all computed, similarity features\n",
    "       :param selected_features: An array of selected features that correspond to certain columns in `features_df`\n",
    "       :return: training and test features and labels: (train_x, train_y), (test_x, test_y)'''\n",
    "    \n",
    "    # get the training features\n",
    "#    train_x = complete_df[complete_df['Datatype']=='train'].drop(['Class'],axis=1)\n",
    "    \n",
    "#    train_x = features_df[[complete_df['Datatype'].values =='train']][selected_features]\n",
    "    df = pd.concat([complete_df, features_df[selected_features]], axis=1)\n",
    "    print('df',df,type(df))\n",
    "    \n",
    "    df_train = df[df.Datatype == 'train']\n",
    "\n",
    "    print()\n",
    "    print('df_train',df_train)\n",
    "\n",
    "    \n",
    "    train_x = df_train[selected_features].values # convert to numpy nd array\n",
    "    train_y = df_train['Class'].values\n",
    "\n",
    "    # And training class labels (0 or 1)\n",
    "    #train_y = complete_df['Class']\n",
    "    print('train_x',train_x,type(train_x))\n",
    "    print()\n",
    "    print('train_y',train_y,type(train_y))\n",
    "\n",
    "\n",
    "    \n",
    "    # get the test features and labels\n",
    "    df_test = df[df.Datatype == 'test']    \n",
    "    print(df_test)\n",
    "    test_x= df_test[selected_features].values #converts to numpy nd array\n",
    "    test_y = df_test['Class'].values #same numpy nd array\n",
    "    print('test_x',test_x,type(test_x))\n",
    "    print()\n",
    "    print('test_y',test_y,type(test_y))\n",
    "    \n",
    "    return (train_x, train_y), (test_x, test_y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cells\n",
    "\n",
    "Below, test out your implementation and create the final train/test data."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "test_selection = list(features_df)[:2] # first couple columns as a test\n",
    "# test that the correct train/test data is created\n",
    "(train_x, train_y), (test_x, test_y) = train_test_data(complete_df, features_df, test_selection)\n",
    "\n",
    "# params: generated train/test data\n",
    "tests.test_data_split(train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE: Select \"good\" features\n",
    "\n",
    "If you passed the test above, you can create your own train/test data, below. \n",
    "\n",
    "Define a list of features you'd like to include in your final mode, `selected_features`; this is a list of the features names you want to include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df               File Task  Category  Class  \\\n",
      "0   g0pA_taska.txt    a         0      0   \n",
      "1   g0pA_taskb.txt    b         3      1   \n",
      "2   g0pA_taskc.txt    c         2      1   \n",
      "3   g0pA_taskd.txt    d         1      1   \n",
      "4   g0pA_taske.txt    e         0      0   \n",
      "..             ...  ...       ...    ...   \n",
      "95  orig_taska.txt    a        -1     -1   \n",
      "96  orig_taskb.txt    b        -1     -1   \n",
      "97  orig_taskc.txt    c        -1     -1   \n",
      "98  orig_taskd.txt    d        -1     -1   \n",
      "99  orig_taske.txt    e        -1     -1   \n",
      "\n",
      "                                                 Text Datatype       c_1  \\\n",
      "0   inheritance is a basic concept of object orien...    train  0.398148   \n",
      "1   pagerank is a link analysis algorithm used by ...     test  1.000000   \n",
      "2   the vector space model also called term vector...    train  0.869369   \n",
      "3   bayes theorem was names after rev thomas bayes...    train  0.593583   \n",
      "4   dynamic programming is an algorithm design tec...    train  0.544503   \n",
      "..                                                ...      ...       ...   \n",
      "95  in object oriented programming inheritance is ...     orig -1.000000   \n",
      "96  pagerank is a link analysis algorithm used by ...     orig -1.000000   \n",
      "97  vector space model or term vector model is an ...     orig -1.000000   \n",
      "98  in probability theory bayes theorem often call...     orig -1.000000   \n",
      "99  in mathematics and computer science dynamic pr...     orig -1.000000   \n",
      "\n",
      "         c_2       c_6  lcs_word  \n",
      "0   0.079070  0.000000  0.191781  \n",
      "1   0.984694  0.901042  0.820755  \n",
      "2   0.719457  0.382488  0.846491  \n",
      "3   0.268817  0.060440  0.316062  \n",
      "4   0.115789  0.000000  0.242574  \n",
      "..       ...       ...       ...  \n",
      "95 -1.000000 -1.000000 -1.000000  \n",
      "96 -1.000000 -1.000000 -1.000000  \n",
      "97 -1.000000 -1.000000 -1.000000  \n",
      "98 -1.000000 -1.000000 -1.000000  \n",
      "99 -1.000000 -1.000000 -1.000000  \n",
      "\n",
      "[100 rows x 10 columns] <class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "df_train               File Task  Category  Class  \\\n",
      "0   g0pA_taska.txt    a         0      0   \n",
      "2   g0pA_taskc.txt    c         2      1   \n",
      "3   g0pA_taskd.txt    d         1      1   \n",
      "4   g0pA_taske.txt    e         0      0   \n",
      "5   g0pB_taska.txt    a         0      0   \n",
      "..             ...  ...       ...    ...   \n",
      "89  g4pD_taske.txt    e         1      1   \n",
      "90  g4pE_taska.txt    a         1      1   \n",
      "91  g4pE_taskb.txt    b         2      1   \n",
      "92  g4pE_taskc.txt    c         3      1   \n",
      "93  g4pE_taskd.txt    d         0      0   \n",
      "\n",
      "                                                 Text Datatype       c_1  \\\n",
      "0   inheritance is a basic concept of object orien...    train  0.398148   \n",
      "2   the vector space model also called term vector...    train  0.869369   \n",
      "3   bayes theorem was names after rev thomas bayes...    train  0.593583   \n",
      "4   dynamic programming is an algorithm design tec...    train  0.544503   \n",
      "5   inheritance is a basic concept in object orien...    train  0.329502   \n",
      "..                                                ...      ...       ...   \n",
      "89  dynamic programming is a method of providing s...    train  0.845188   \n",
      "90  object oriented programming is a style of prog...    train  0.485000   \n",
      "91  pagerankalgorithm is also known as link analys...    train  0.950673   \n",
      "92  the definition of term depends on the applicat...    train  0.551220   \n",
      "93   bayes theorem or bayes rule  or something cal...    train  0.361257   \n",
      "\n",
      "         c_2       c_6  lcs_word  \n",
      "0   0.079070  0.000000  0.191781  \n",
      "2   0.719457  0.382488  0.846491  \n",
      "3   0.268817  0.060440  0.316062  \n",
      "4   0.115789  0.000000  0.242574  \n",
      "5   0.053846  0.000000  0.161172  \n",
      "..       ...       ...       ...  \n",
      "89  0.546218  0.273504  0.643725  \n",
      "90  0.105528  0.000000  0.242718  \n",
      "91  0.878378  0.761468  0.839506  \n",
      "92  0.328431  0.220000  0.283019  \n",
      "93  0.031579  0.000000  0.161765  \n",
      "\n",
      "[70 rows x 10 columns]\n",
      "train_x [[0.39814815 0.07906977 0.         0.19178082]\n",
      " [0.86936937 0.71945701 0.38248848 0.84649123]\n",
      " [0.59358289 0.2688172  0.06043956 0.31606218]\n",
      " [0.54450262 0.11578947 0.         0.24257426]\n",
      " [0.32950192 0.05384615 0.         0.16117216]\n",
      " [0.59030837 0.15044248 0.         0.30165289]\n",
      " [0.75977654 0.50561798 0.1954023  0.48430493]\n",
      " [0.51612903 0.07027027 0.         0.27083333]\n",
      " [0.44086022 0.11891892 0.         0.22395833]\n",
      " [0.97945205 0.91724138 0.74468085 0.9       ]\n",
      " [0.95138889 0.7972028  0.45323741 0.89403974]\n",
      " [0.97647059 0.85798817 0.5030303  0.82320442]\n",
      " [0.81176471 0.55621302 0.23636364 0.45977011]\n",
      " [0.44117647 0.03030303 0.         0.30555556]\n",
      " [0.48888889 0.06741573 0.         0.2826087 ]\n",
      " [0.81395349 0.67058824 0.62962963 0.78888889]\n",
      " [0.61111111 0.15492958 0.         0.32467532]\n",
      " [1.         1.         0.95402299 1.        ]\n",
      " [0.63402062 0.20207254 0.         0.36893204]\n",
      " [0.58293839 0.29047619 0.05339806 0.41666667]\n",
      " [0.63793103 0.42857143 0.29515419 0.48987854]\n",
      " [0.42038217 0.07692308 0.         0.21875   ]\n",
      " [0.68776371 0.40677966 0.04741379 0.51639344]\n",
      " [0.67664671 0.31927711 0.08641975 0.47252747]\n",
      " [0.76923077 0.53355705 0.44217687 0.60645161]\n",
      " [0.71226415 0.37914692 0.05797101 0.53669725]\n",
      " [0.62992126 0.33992095 0.27309237 0.3943662 ]\n",
      " [0.71573604 0.26020408 0.         0.34313725]\n",
      " [0.33206107 0.03065134 0.         0.15302491]\n",
      " [0.71721311 0.36213992 0.05857741 0.4559387 ]\n",
      " [0.87826087 0.71179039 0.42222222 0.82      ]\n",
      " [0.52980132 0.35548173 0.30976431 0.45      ]\n",
      " [0.57211538 0.14009662 0.         0.2293578 ]\n",
      " [0.31967213 0.04115226 0.         0.16535433]\n",
      " [0.53       0.13567839 0.         0.26046512]\n",
      " [0.78       0.65829146 0.59487179 0.66990291]\n",
      " [0.65269461 0.18674699 0.         0.35519126]\n",
      " [0.44394619 0.15315315 0.         0.23376623]\n",
      " [0.66502463 0.39108911 0.14646465 0.34926471]\n",
      " [0.72815534 0.30731707 0.01492537 0.34761905]\n",
      " [0.76204819 0.54984894 0.24464832 0.56772334]\n",
      " [0.94701987 0.67333333 0.21232877 0.77439024]\n",
      " [0.36842105 0.0619469  0.         0.19298246]\n",
      " [0.53289474 0.09933775 0.         0.21818182]\n",
      " [0.61849711 0.16860465 0.         0.26666667]\n",
      " [0.51030928 0.09326425 0.00529101 0.22110553]\n",
      " [0.57983193 0.11814346 0.         0.22891566]\n",
      " [0.40703518 0.06565657 0.         0.1722488 ]\n",
      " [0.51546392 0.09310345 0.         0.23684211]\n",
      " [0.58454106 0.27669903 0.02475248 0.29493088]\n",
      " [0.6171875  0.33858268 0.13821138 0.5037594 ]\n",
      " [1.         0.96153846 0.8015873  0.91176471]\n",
      " [0.99166667 0.96638655 0.86086957 0.99230769]\n",
      " [0.5505618  0.15819209 0.         0.28333333]\n",
      " [0.41935484 0.07608696 0.         0.26168224]\n",
      " [0.83516484 0.45555556 0.         0.64705882]\n",
      " [0.92708333 0.69473684 0.20879121 0.85      ]\n",
      " [0.492891   0.05714286 0.         0.23502304]\n",
      " [0.70873786 0.52682927 0.27363184 0.66197183]\n",
      " [0.86338798 0.66483516 0.23595506 0.79111111]\n",
      " [0.96060606 0.92097264 0.84923077 0.92982456]\n",
      " [0.43801653 0.08333333 0.         0.22307692]\n",
      " [0.73366834 0.35353535 0.03608247 0.49009901]\n",
      " [0.51388889 0.09302326 0.         0.25203252]\n",
      " [0.48611111 0.07906977 0.         0.22767857]\n",
      " [0.84518828 0.54621849 0.27350427 0.6437247 ]\n",
      " [0.485      0.10552764 0.         0.24271845]\n",
      " [0.95067265 0.87837838 0.76146789 0.83950617]\n",
      " [0.55121951 0.32843137 0.22       0.28301887]\n",
      " [0.36125654 0.03157895 0.         0.16176471]] <class 'numpy.ndarray'>\n",
      "\n",
      "train_y [0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0\n",
      " 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0] <class 'numpy.ndarray'>\n",
      "              File Task  Category  Class  \\\n",
      "1   g0pA_taskb.txt    b         3      1   \n",
      "7   g0pB_taskc.txt    c         3      1   \n",
      "9   g0pB_taske.txt    e         1      1   \n",
      "10  g0pC_taska.txt    a         1      1   \n",
      "16  g0pD_taskb.txt    b         2      1   \n",
      "20  g0pE_taska.txt    a         2      1   \n",
      "23  g0pE_taskd.txt    d         0      0   \n",
      "25  g1pA_taska.txt    a         0      0   \n",
      "29  g1pA_taske.txt    e         0      0   \n",
      "31  g1pB_taskb.txt    b         0      0   \n",
      "37  g1pD_taskc.txt    c         0      0   \n",
      "38  g1pD_taskd.txt    d         0      0   \n",
      "47  g2pB_taskc.txt    c         1      1   \n",
      "48  g2pB_taskd.txt    d         2      1   \n",
      "49  g2pB_taske.txt    e         3      1   \n",
      "61  g3pA_taskb.txt    b         1      1   \n",
      "62  g3pA_taskc.txt    c         2      1   \n",
      "63  g3pA_taskd.txt    d         3      1   \n",
      "75  g4pB_taska.txt    a         0      0   \n",
      "80  g4pC_taska.txt    a         3      1   \n",
      "81  g4pC_taskb.txt    b         0      0   \n",
      "83  g4pC_taskd.txt    d         1      1   \n",
      "84  g4pC_taske.txt    e         2      1   \n",
      "87  g4pD_taskc.txt    c         0      0   \n",
      "94  g4pE_taske.txt    e         0      0   \n",
      "\n",
      "                                                 Text Datatype       c_1  \\\n",
      "1   pagerank is a link analysis algorithm used by ...     test  1.000000   \n",
      "7   vector space model is an algebraic model for r...     test  0.765306   \n",
      "9   dynamic programming is a method for solving ma...     test  0.884444   \n",
      "10  inheritance in object oriented programming is ...     test  0.619048   \n",
      "16  pagerank algorithm is patented by stanford uni...     test  0.920000   \n",
      "20  in object oriented programming inheritance is ...     test  0.992674   \n",
      "23  bayes theorem is an important theorem relating...     test  0.412698   \n",
      "25  in object oriented programming objects are gro...     test  0.462687   \n",
      "29  dynamic programming is an algorithmic techniqu...     test  0.581152   \n",
      "31  a websites page rank is how important it is on...     test  0.584211   \n",
      "37  within information retrieval each document in ...     test  0.566372   \n",
      "38  bayes theorem is a mathematical formula used t...     test  0.481481   \n",
      "47  a vector space model is an algebraic model for...     test  0.619792   \n",
      "48   in probability theory bayes theorem also call...     test  0.921739   \n",
      "49   in mathematics and computer science dynamic p...     test  1.000000   \n",
      "61  the google search engine uses a link analysis ...     test  0.861538   \n",
      "62  vector space model or term vector model as it ...     test  0.626168   \n",
      "63  in probability theory bayes theorem often call...     test  1.000000   \n",
      "75  inheritance is the ability of a subclass to in...     test  0.383838   \n",
      "80  in object oriented programming inheritance is ...     test  1.000000   \n",
      "81  since the develop of the web 2 0 google as one...     test  0.613924   \n",
      "83  in probability theory bayes theorem relates th...     test  0.972763   \n",
      "84  in mathematics and computer science dynamic pr...     test  0.962810   \n",
      "87  in vector space model the documents from which...     test  0.415254   \n",
      "94   dynamic programming is a method for efficient...     test  0.532189   \n",
      "\n",
      "         c_2       c_6  lcs_word  \n",
      "1   0.984694  0.901042  0.820755  \n",
      "7   0.709898  0.553633  0.621711  \n",
      "9   0.526786  0.150000  0.597458  \n",
      "10  0.250000  0.021739  0.427835  \n",
      "16  0.675676  0.328571  0.775000  \n",
      "20  0.985294  0.970149  0.993056  \n",
      "23  0.112903  0.000000  0.346667  \n",
      "25  0.070000  0.000000  0.189320  \n",
      "29  0.142105  0.000000  0.247423  \n",
      "31  0.142857  0.000000  0.294416  \n",
      "37  0.151786  0.000000  0.258333  \n",
      "38  0.171642  0.007692  0.278912  \n",
      "47  0.251309  0.021390  0.341584  \n",
      "48  0.842795  0.600000  0.929412  \n",
      "49  0.980843  0.902724  1.000000  \n",
      "61  0.396907  0.042105  0.504717  \n",
      "62  0.465625  0.170886  0.558559  \n",
      "63  0.992308  0.960938  0.996700  \n",
      "75  0.076142  0.005181  0.178744  \n",
      "80  0.989051  0.929630  0.854671  \n",
      "81  0.133758  0.000000  0.298343  \n",
      "83  0.937500  0.793651  0.927083  \n",
      "84  0.867220  0.641350  0.909804  \n",
      "87  0.102128  0.000000  0.177419  \n",
      "94  0.163793  0.013158  0.245833  \n",
      "test_x [[1.         0.98469388 0.90104167 0.82075472]\n",
      " [0.76530612 0.70989761 0.55363322 0.62171053]\n",
      " [0.88444444 0.52678571 0.15       0.59745763]\n",
      " [0.61904762 0.25       0.02173913 0.42783505]\n",
      " [0.92       0.67567568 0.32857143 0.775     ]\n",
      " [0.99267399 0.98529412 0.97014925 0.99305556]\n",
      " [0.41269841 0.11290323 0.         0.34666667]\n",
      " [0.46268657 0.07       0.         0.18932039]\n",
      " [0.58115183 0.14210526 0.         0.24742268]\n",
      " [0.58421053 0.14285714 0.         0.29441624]\n",
      " [0.56637168 0.15178571 0.         0.25833333]\n",
      " [0.48148148 0.17164179 0.00769231 0.27891156]\n",
      " [0.61979167 0.2513089  0.02139037 0.34158416]\n",
      " [0.92173913 0.84279476 0.6        0.92941176]\n",
      " [1.         0.98084291 0.90272374 1.        ]\n",
      " [0.86153846 0.39690722 0.04210526 0.50471698]\n",
      " [0.62616822 0.465625   0.17088608 0.55855856]\n",
      " [1.         0.99230769 0.9609375  0.99669967]\n",
      " [0.38383838 0.07614213 0.00518135 0.17874396]\n",
      " [1.         0.98905109 0.92962963 0.85467128]\n",
      " [0.61392405 0.13375796 0.         0.29834254]\n",
      " [0.97276265 0.9375     0.79365079 0.92708333]\n",
      " [0.96280992 0.86721992 0.64135021 0.90980392]\n",
      " [0.41525424 0.10212766 0.         0.17741935]\n",
      " [0.53218884 0.1637931  0.01315789 0.24583333]] <class 'numpy.ndarray'>\n",
      "\n",
      "test_y [1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0] <class 'numpy.ndarray'>\n",
      "Training size:  70\n",
      "Test size:  25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select your list of features, this should be column names from features_df\n",
    "# ex. ['c_1', 'lcs_word']\n",
    " # c_1 is the containment features, lcs_word is the list of words features\n",
    "#selected_features = ['c_1', 'lcs_word']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = train_test_data(complete_df, features_df, selected_features)\n",
    "\n",
    "# check that division of samples seems correct\n",
    "# these should add up to 95 (100 - 5 original files)\n",
    "print('Training size: ', len(train_x))\n",
    "print('Test size: ', len(test_x))\n",
    "print()\n",
    "#print('Training df sample: \\n', train_x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.39814815 0.07906977 0.         0.19178082]\n",
      " [0.86936937 0.71945701 0.38248848 0.84649123]\n",
      " [0.59358289 0.2688172  0.06043956 0.31606218]\n",
      " [0.54450262 0.11578947 0.         0.24257426]\n",
      " [0.32950192 0.05384615 0.         0.16117216]\n",
      " [0.59030837 0.15044248 0.         0.30165289]\n",
      " [0.75977654 0.50561798 0.1954023  0.48430493]\n",
      " [0.51612903 0.07027027 0.         0.27083333]\n",
      " [0.44086022 0.11891892 0.         0.22395833]\n",
      " [0.97945205 0.91724138 0.74468085 0.9       ]\n",
      " [0.95138889 0.7972028  0.45323741 0.89403974]\n",
      " [0.97647059 0.85798817 0.5030303  0.82320442]\n",
      " [0.81176471 0.55621302 0.23636364 0.45977011]\n",
      " [0.44117647 0.03030303 0.         0.30555556]\n",
      " [0.48888889 0.06741573 0.         0.2826087 ]\n",
      " [0.81395349 0.67058824 0.62962963 0.78888889]\n",
      " [0.61111111 0.15492958 0.         0.32467532]\n",
      " [1.         1.         0.95402299 1.        ]\n",
      " [0.63402062 0.20207254 0.         0.36893204]\n",
      " [0.58293839 0.29047619 0.05339806 0.41666667]\n",
      " [0.63793103 0.42857143 0.29515419 0.48987854]\n",
      " [0.42038217 0.07692308 0.         0.21875   ]\n",
      " [0.68776371 0.40677966 0.04741379 0.51639344]\n",
      " [0.67664671 0.31927711 0.08641975 0.47252747]\n",
      " [0.76923077 0.53355705 0.44217687 0.60645161]\n",
      " [0.71226415 0.37914692 0.05797101 0.53669725]\n",
      " [0.62992126 0.33992095 0.27309237 0.3943662 ]\n",
      " [0.71573604 0.26020408 0.         0.34313725]\n",
      " [0.33206107 0.03065134 0.         0.15302491]\n",
      " [0.71721311 0.36213992 0.05857741 0.4559387 ]\n",
      " [0.87826087 0.71179039 0.42222222 0.82      ]\n",
      " [0.52980132 0.35548173 0.30976431 0.45      ]\n",
      " [0.57211538 0.14009662 0.         0.2293578 ]\n",
      " [0.31967213 0.04115226 0.         0.16535433]\n",
      " [0.53       0.13567839 0.         0.26046512]\n",
      " [0.78       0.65829146 0.59487179 0.66990291]\n",
      " [0.65269461 0.18674699 0.         0.35519126]\n",
      " [0.44394619 0.15315315 0.         0.23376623]\n",
      " [0.66502463 0.39108911 0.14646465 0.34926471]\n",
      " [0.72815534 0.30731707 0.01492537 0.34761905]\n",
      " [0.76204819 0.54984894 0.24464832 0.56772334]\n",
      " [0.94701987 0.67333333 0.21232877 0.77439024]\n",
      " [0.36842105 0.0619469  0.         0.19298246]\n",
      " [0.53289474 0.09933775 0.         0.21818182]\n",
      " [0.61849711 0.16860465 0.         0.26666667]\n",
      " [0.51030928 0.09326425 0.00529101 0.22110553]\n",
      " [0.57983193 0.11814346 0.         0.22891566]\n",
      " [0.40703518 0.06565657 0.         0.1722488 ]\n",
      " [0.51546392 0.09310345 0.         0.23684211]\n",
      " [0.58454106 0.27669903 0.02475248 0.29493088]\n",
      " [0.6171875  0.33858268 0.13821138 0.5037594 ]\n",
      " [1.         0.96153846 0.8015873  0.91176471]\n",
      " [0.99166667 0.96638655 0.86086957 0.99230769]\n",
      " [0.5505618  0.15819209 0.         0.28333333]\n",
      " [0.41935484 0.07608696 0.         0.26168224]\n",
      " [0.83516484 0.45555556 0.         0.64705882]\n",
      " [0.92708333 0.69473684 0.20879121 0.85      ]\n",
      " [0.492891   0.05714286 0.         0.23502304]\n",
      " [0.70873786 0.52682927 0.27363184 0.66197183]\n",
      " [0.86338798 0.66483516 0.23595506 0.79111111]\n",
      " [0.96060606 0.92097264 0.84923077 0.92982456]\n",
      " [0.43801653 0.08333333 0.         0.22307692]\n",
      " [0.73366834 0.35353535 0.03608247 0.49009901]\n",
      " [0.51388889 0.09302326 0.         0.25203252]\n",
      " [0.48611111 0.07906977 0.         0.22767857]\n",
      " [0.84518828 0.54621849 0.27350427 0.6437247 ]\n",
      " [0.485      0.10552764 0.         0.24271845]\n",
      " [0.95067265 0.87837838 0.76146789 0.83950617]\n",
      " [0.55121951 0.32843137 0.22       0.28301887]\n",
      " [0.36125654 0.03157895 0.         0.16176471]]\n"
     ]
    }
   ],
   "source": [
    "print(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: How did you decide on which features to include in your final model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "I compared the corelation between features by using a nested for loop for the matrix. Initially i had to set all columns to True and place false on the threshold of 1.0 or above. Therefore, I got selected features: c_1, c_2, c_6 and lcs_word. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Creating Final Data Files\n",
    "\n",
    "Now, you are almost ready to move on to training a model in SageMaker!\n",
    "\n",
    "You'll want to access your train and test data in SageMaker and upload it to S3. In this project, SageMaker will expect the following format for your train/test data:\n",
    "* Training and test data should be saved in one `.csv` file each, ex `train.csv` and `test.csv`\n",
    "* These files should have class  labels in the first column and features in the rest of the columns\n",
    "\n",
    "This format follows the practice, outlined in the [SageMaker documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html), which reads: \"Amazon SageMaker requires that a CSV file doesn't have a header record and that the target variable [class label] is in the first column.\"\n",
    "\n",
    "## EXERCISE: Create csv files\n",
    "\n",
    "Define a function that takes in x (features) and y (labels) and saves them to one `.csv` file at the path `data_dir/filename`.\n",
    "\n",
    "It may be useful to use pandas to merge your features and labels into one DataFrame and then convert that into a csv file. You can make sure to get rid of any incomplete rows, in a DataFrame, by using `dropna`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv(x, y, filename, data_dir):\n",
    "    '''Merges features and labels and converts them into one csv file with labels in the first column.\n",
    "       :param x: Data features\n",
    "       :param y: Data labels\n",
    "       :param file_name: Name of csv file, ex. 'train.csv'\n",
    "       :param data_dir: The directory where files will be saved\n",
    "       '''\n",
    "    # make data dir, if it does not exist\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    # first column is the labels and rest is features \n",
    "    pd.concat([pd.DataFrame(y), pd.DataFrame(x)], axis=1)\\\n",
    "             .to_csv(os.path.join(data_dir, filename), header=False, index=False)\n",
    "    \n",
    "    # nothing is returned, but a print statement indicates that the function has run\n",
    "    print('Path created: '+str(data_dir)+'/'+str(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cells\n",
    "\n",
    "Test that your code produces the correct format for a `.csv` file, given some text features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path created: test_csv/to_delete.csv\n",
      "Tests passed!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "fake_x = [ [0.39814815, 0.0001, 0.19178082], \n",
    "           [0.86936937, 0.44954128, 0.84649123], \n",
    "           [0.44086022, 0., 0.22395833] ]\n",
    "\n",
    "fake_y = [0, 1, 1]\n",
    "\n",
    "make_csv(fake_x, fake_y, filename='to_delete.csv', data_dir='test_csv')\n",
    "\n",
    "# read in and test dimensions\n",
    "fake_df = pd.read_csv('test_csv/to_delete.csv', header=None)\n",
    "\n",
    "# check shape\n",
    "assert fake_df.shape==(3, 4), \\\n",
    "      'The file should have as many rows as data_points and as many columns as features+1 (for indices).'\n",
    "# check that first column = labels\n",
    "assert np.all(fake_df.iloc[:,0].values==fake_y), 'First column is not equal to the labels, fake_y.'\n",
    "print('Tests passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the test csv file, generated above\n",
    "! rm -rf test_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've passed the tests above, run the following cell to create `train.csv` and `test.csv` files in a directory that you specify! This will save the data in a local directory. Remember the name of this directory because you will reference it again when uploading this data to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path created: plagiarism_data/train.csv\n",
      "Path created: plagiarism_data/test.csv\n"
     ]
    }
   ],
   "source": [
    "# can change directory, if you want\n",
    "data_dir = 'plagiarism_data'\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "make_csv(train_x, train_y, filename='train.csv', data_dir=data_dir)\n",
    "make_csv(test_x, test_y, filename='test.csv', data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up Next\n",
    "\n",
    "Now that you've done some feature engineering and created some training and test data, you are ready to train and deploy a plagiarism classification model. The next notebook will utilize SageMaker resources to train and test a model that you design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
